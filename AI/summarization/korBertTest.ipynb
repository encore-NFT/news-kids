{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KorBertSum 문서 추출요약"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (1) Pre-trained BERT Model\n",
    "\n",
    "BERT fine-tuning을 위해서는 먼저 사전학습된 BERT 모델이 필요\n",
    "\n",
    "- [ETRI 홈페이지](https://aiopen.etri.re.kr/service_dataset.php)에서 모델 사용신청을 하여 BERT Model을 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "├─ 001_bert_morp_pytorch\n",
    "│   ├── KorBERT_FAQ_20190619.pdf\n",
    "│   ├── bert_config.json\n",
    "│   ├── pytorch_model.bin\n",
    "│   ├── readme.txt\n",
    "│   ├── src_examples\n",
    "│   ├── src_tokenizer\n",
    "│   └── vocab.korean_morp.list\n",
    "└── 002_bert_morp_tensorflow\n",
    "    ├── KorBERT_FAQ_20190619.pdf\n",
    "    ├── bert_config.json\n",
    "    ├── model.ckpt.data-00000-of-00001\n",
    "    ├── model.ckpt.index\n",
    "    ├── model.ckpt.meta\n",
    "    ├── src_tokenizer\n",
    "    └── vocab.korean_morp.list\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Train Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Dacon 문서 추출요약 AI 경진대회](https://dacon.io/competitions/official/235671/data) 의 데이터 셋 활용 _-> 현재 대회종료로 data 제공 안하고 있음_\n",
    "\n",
    "    **train.jsonl** :  학습에 사용 할 데이터셋\n",
    "\n",
    "    - media : 기사 미디어\n",
    "\n",
    "    - id : 각 데이터 고유 번호\n",
    "\n",
    "    - article_original : 전체 기사 내용, 문장별로 split되어 있음\n",
    "\n",
    "    - abstractive : 사람이 생성한 요약문\n",
    "\n",
    "    - extractive : 사람이 추출한 요약문 3개의 index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. [AI Hub](https://aihub.or.kr/aidata/8054)의 데이터 셋 활용\n",
    "- 해당 json 데이터를 대회에서 쓰인 데이터 형태로 파싱해서 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "├── Training\n",
    "│   ├── train_original.json\n",
    "│   ├── 법률_train_original.zip\n",
    "│   ├── 사설_train_original.zip\n",
    "│   └── 신문기사_train_original.zip\n",
    "└── Validation\n",
    "    ├── valid_original.json\n",
    "    ├── 법률_valid_original.zip\n",
    "    ├── 사설_valid_original.zip\n",
    "    └── 신문기사_valid_original.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (1) sample.jsonl 파일 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/imok/workspace/github/imOk/AI/KorBertSum\n"
     ]
    }
   ],
   "source": [
    "cd /Users/imok/workspace/github/imOk/AI/KorBertSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../sample.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "result = []\n",
    "for json_str in json_list:\n",
    "    result.append(json.loads(json_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>abstractive</th>\n",
       "      <th>extractive</th>\n",
       "      <th>article_original</th>\n",
       "      <th>media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>353465974</td>\n",
       "      <td>충주시는 민간보조사업의 증가와 보조금 집행관리에 대한 부당 행위가 증가함에따라 15...</td>\n",
       "      <td>[2, 3, 5]</td>\n",
       "      <td>[보조금 집행 위법행위·지적사례 늘어, 특별감사반, 2017~2018년 축제 점검,...</td>\n",
       "      <td>충청투데이</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>366398381</td>\n",
       "      <td>국무조정실은 8일 오후 대전시청에서 '대전지역 규제혁신 현장간담회'를 열고 대전과 ...</td>\n",
       "      <td>[4, 6, 14]</td>\n",
       "      <td>[8일 대전시청에서 규제혁신 간담회, 도시개발 산업용지도 특화단지 지정가능, 국무조...</td>\n",
       "      <td>중도일보</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360025161</td>\n",
       "      <td>중국 경제일간지 21세기경제보도는 중국 대형 생명보험사인 차이나라이프가 '차이나라이...</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>[중국 경제일간지 21세기경제보도는 중국 대형 생명보험사인 차이나라이프(中國人壽)가...</td>\n",
       "      <td>내일신문</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>361884128</td>\n",
       "      <td>1일 대검찰청은 '조속한 검찰개혁 방안을 마련하라'는 문재인 대통령의 지시에 따라...</td>\n",
       "      <td>[4, 5, 3]</td>\n",
       "      <td>[전승표 기자, 대검, 文 지시에 발빠른 방안 마련 서울중앙지검 3곳 빼고 모두 폐...</td>\n",
       "      <td>기호일보</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>351452460</td>\n",
       "      <td>제주도가 민선 7기 출범과 함께 조직개편을 추진하면서 지난해 8월 공무원 정원을 2...</td>\n",
       "      <td>[6, 11, 7]</td>\n",
       "      <td>[제주도가 공무원 정원 102명 증원을 추진하고 있는 가운데 제주도청 조직 및 인력...</td>\n",
       "      <td>한라일보</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                        abstractive  extractive  \\\n",
       "0  353465974  충주시는 민간보조사업의 증가와 보조금 집행관리에 대한 부당 행위가 증가함에따라 15...   [2, 3, 5]   \n",
       "1  366398381  국무조정실은 8일 오후 대전시청에서 '대전지역 규제혁신 현장간담회'를 열고 대전과 ...  [4, 6, 14]   \n",
       "2  360025161  중국 경제일간지 21세기경제보도는 중국 대형 생명보험사인 차이나라이프가 '차이나라이...   [0, 1, 2]   \n",
       "3  361884128   1일 대검찰청은 '조속한 검찰개혁 방안을 마련하라'는 문재인 대통령의 지시에 따라...   [4, 5, 3]   \n",
       "4  351452460  제주도가 민선 7기 출범과 함께 조직개편을 추진하면서 지난해 8월 공무원 정원을 2...  [6, 11, 7]   \n",
       "\n",
       "                                    article_original  media  \n",
       "0  [보조금 집행 위법행위·지적사례 늘어, 특별감사반, 2017~2018년 축제 점검,...  충청투데이  \n",
       "1  [8일 대전시청에서 규제혁신 간담회, 도시개발 산업용지도 특화단지 지정가능, 국무조...   중도일보  \n",
       "2  [중국 경제일간지 21세기경제보도는 중국 대형 생명보험사인 차이나라이프(中國人壽)가...   내일신문  \n",
       "3  [전승표 기자, 대검, 文 지시에 발빠른 방안 마련 서울중앙지검 3곳 빼고 모두 폐...   기호일보  \n",
       "4  [제주도가 공무원 정원 102명 증원을 추진하고 있는 가운데 제주도청 조직 및 인력...   한라일보  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(result)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['보조금 집행 위법행위·지적사례 늘어',\n",
       " '특별감사반, 2017~2018년 축제 점검',\n",
       " '충주시가 민간에게 지원되는 보조사업의 대형축제와 관련해 선정·집행·정산 등 운영실태 전반에 대한 자체 감사를 실시할 계획이라고 밝혔다.',\n",
       " '이는 최근 민간보조사업의 증가와 더불어 보조금 집행관리에 대한 위법 부당 행위와 지적사례가 지속적으로 증가함에 따라, 감사를 통해 취약요인을 점검해 올바른 보조금 사용 풍토를 정착시키겠다는 취지다.',\n",
       " '시는 감사담당관실과 기획예산과 보조금 관련 주무관으로 특별감사반을 편성해 2017년부터 2018년까지 집행된 축제성 보조금 집행에 대한 철저한 점검과 감사를 통해 부정 수급 및 부정 집행이 확인되면 엄정한 조치를 취할 방침이다.',\n",
       " '시는 지난 15일부터 25일까지 10일간의 사전감사를 통해 보조금 실태를 파악한 후, 8월15일까지 세부감사를 진행할 예정이라고 전했다.',\n",
       " '축제성 관련 부정수급 유형을 보면 허위·기타 부정한 방법으로 보조금 신청, 사업 실적을 부풀려 보조금을 횡령·편취, 보조금 교부 목적과 다른 용도로 집행, 보조금으로 취득한 재산에 대해 지자체장의 승인없이 임의 처분 등이 해당된다.',\n",
       " \"시는 불법보조금 근절과 효율적인 점검 및 적극적인 시민관심을 유도하기 위해 '지방보조금 부정수급 신고센터(☏850-5031)'를 설치 운영하고 있다.\",\n",
       " '지방보조금 부정수급 신고 시 직접방문 및 국민신문고(www.epeople.or.kr), 충주시홈페이지(www.chungju.or.kr)를 통해 접수하면 되고, 신고취지와 이유를 기재하고 부정행위와 관련한 증거자료를 제시하면 된다.',\n",
       " '단, 익명 신고는 접수치 않는다.',\n",
       " '시 관계자는 \"이번 자체 점검 및 감사를 통해 축제보조금이 제대로 쓰이는지에 대한 반성과 함께 보조금 집행의 투명성 및 행정의 신뢰성을 확보하는데 최선을 다하겠다\"고 말했다.',\n",
       " '한편. 시는 감사 및 예산부서 합동으로 컨설팅 위주의 상반기 보조금 특정감사(1월10일~20일)를 실시해 주의 11건, 시정 6건, 권고 1건을 자체 적발하고 조치한 바 있다.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.article_original[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 신문기사 train data 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import OrderedDict \n",
    "import pprint\n",
    "\n",
    "with open('../text/Training/train_original.json') as json_file:\n",
    "    jsonObject = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '290741778',\n",
       "  'category': '종합',\n",
       "  'media_type': 'online',\n",
       "  'media_sub_type': '지역지',\n",
       "  'media_name': '광양신문',\n",
       "  'size': 'small',\n",
       "  'char_count': '927',\n",
       "  'publish_date': '2018-01-05 18:54:55',\n",
       "  'title': '논 타작물 재배, 2월 말까지 신청하세요',\n",
       "  'text': [[{'index': 0,\n",
       "     'sentence': 'ha당 조사료 400만원…작물별 차등 지원',\n",
       "     'highlight_indices': ''}],\n",
       "   [{'index': 1,\n",
       "     'sentence': '이성훈 sinawi@hanmail.net',\n",
       "     'highlight_indices': ''}],\n",
       "   [{'index': 2,\n",
       "     'sentence': '전라남도가 쌀 과잉문제를 근본적으로 해결하기 위해 올해부터 시행하는 쌀 생산조정제를 적극 추진키로 했다.',\n",
       "     'highlight_indices': ''}],\n",
       "   [{'index': 3,\n",
       "     'sentence': '쌀 생산조정제는 벼를 심었던 논에 벼 대신 사료작물이나 콩 등 다른 작물을 심으면 벼와의 일정 소득차를 보전해주는 제도다.',\n",
       "     'highlight_indices': '35,37'}],\n",
       "   [{'index': 4,\n",
       "     'sentence': '올해 전남의 논 다른 작물 재배 계획면적은 전국 5만ha의 약 21%인 1만 698ha로, 세부시행지침을 확정, 시군에 통보했다.',\n",
       "     'highlight_indices': '9,11;33,34'},\n",
       "    {'index': 5,\n",
       "     'sentence': '지원사업 대상은 2017년산 쌀 변동직불금을 받은 농지에 10a(300평) 이상 벼 이외 다른 작물을 재배한 농업인이다.',\n",
       "     'highlight_indices': '50,52'}],\n",
       "   [{'index': 6,\n",
       "     'sentence': '지원 대상 작물은 1년생을 포함한 다년생의 모든 작물이 해당되나 재배 면적 확대 시 수급과잉이 우려되는 고추, 무, 배추, 인삼, 대파 등 수급 불안 품목은 제외된다.',\n",
       "     'highlight_indices': '24,26'}],\n",
       "   [{'index': 7,\n",
       "     'sentence': '농지의 경우도 이미 다른 작물 재배 의무가 부여된 간척지, 정부매입비축농지, 농진청 시범사업, 경관보전 직불금 수령 농지 등은 제외될 예정이다.',\n",
       "     'highlight_indices': '8,10;11,13'}],\n",
       "   [{'index': 8,\n",
       "     'sentence': 'ha(3000평)당 지원 단가는 평균 340만원으로 사료작물 400만원, 일반작물은 340만원, 콩·팥 등 두류작물은 280만원 등이다.',\n",
       "     'highlight_indices': ''},\n",
       "    {'index': 9,\n",
       "     'sentence': '벼와 소득차와 영농 편이성을 감안해 작물별로 차등 지원된다.',\n",
       "     'highlight_indices': ''}],\n",
       "   [{'index': 10,\n",
       "     'sentence': '논에 다른 작물 재배를 바라는 농가는 오는 22일부터 2월 28일까지 농지 소재지 읍면동사무소에 신청해야 한다.',\n",
       "     'highlight_indices': '3,5'}],\n",
       "   [{'index': 11,\n",
       "     'sentence': '전남도는 도와 시군에 관련 기관과 농가 등이 참여하는‘논 타작물 지원사업 추진협의회’를 구성, 지역 특성에 맞는 작목 선정 및 사업 심의 등을 본격 추진할 방침이다.',\n",
       "     'highlight_indices': '32,33;69,70'}],\n",
       "   [{'index': 12,\n",
       "     'sentence': '최향철 전라남도 친환경농업과장은 “최근 쌀값이 다소 상승추세에 있으나 매년 공급과잉에 따른 가격 하락으로 쌀농가에 어려움이 있었다”며“쌀 공급과잉을 구조적으로 해결하도록 논 타작물 재배 지원사업에 많이 참여해주길 바란다”고 말했다.',\n",
       "     'highlight_indices': '26,28;39,41;97,98;110,112'}]],\n",
       "  'annotator_id': 11,\n",
       "  'document_quality_scores': {'readable': 4,\n",
       "   'accurate': 3,\n",
       "   'informative': 3,\n",
       "   'trustworthy': 3},\n",
       "  'extractive': [2, 3, 10],\n",
       "  'abstractive': [\"전라남도가 쌀 과잉문제를 근본적으로 해결하기 위해 올해부터 벼를 심었던 논에 벼 대신 사료작물이나 콩 등 다른 작물을 심으면 벼와의 일정 소득차를 보전해주는 '쌀 생산조정제'를 적극적으로 시행하기로 하고 오는 22일부터 2월 28일까지 농지 소재지 읍면동사무소에서 신청받는다 .\"]}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonArray = jsonObject['documents']\n",
    "jsonArray[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['290741778', '290741792', '290741793', '290741794', '290741797']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = []\n",
    "for name in jsonArray:\n",
    "    id.append(name['id'])\n",
    "id[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['광양신문', '광양신문', '광양신문', '광양신문', '광양신문']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media = []\n",
    "for name in jsonArray:\n",
    "    media.append(name['media_name'])\n",
    "media[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"전라남도가 쌀 과잉문제를 근본적으로 해결하기 위해 올해부터 벼를 심었던 논에 벼 대신 사료작물이나 콩 등 다른 작물을 심으면 벼와의 일정 소득차를 보전해주는 '쌀 생산조정제'를 적극적으로 시행하기로 하고 오는 22일부터 2월 28일까지 농지 소재지 읍면동사무소에서 신청받는다 .\",\n",
       " '여수시는 컬러빌리지 사업에 8억원을 투입하여 ‘색채와 빛’ 도시를 완성하여 고소천사벽화마을과 자산마을은 알록달록 색깔 옷을 입었고 사업 시행과 준공 과정에서도 주민들의 참여를 유도해 경관사업의 좋은 사례를 만들었다.',\n",
       " '전남드래곤즈 임직원과 선수단이 4일 구봉산 정상에 올라 일출을 보며 2018년 구단 목표 달성을 위한 새해 각오를 다졌다.',\n",
       " '광양시는 농업인들의 경쟁력을 높이고, 소득안정을 위해 매실·감·참다래 등 지역특화작목 중심으로 농업인 실용교육을 실시한다.',\n",
       " '올해 4월과 6월 두 차례에 걸쳐 타이완의 크루즈 관광객 4000여명이 여수에 입항해 전남의 관광지를 방문할 예정이다.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstractive = []\n",
    "for name in jsonArray:\n",
    "    abstractive.append(*name['abstractive'])\n",
    "abstractive[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 10], [2, 4, 11], [3, 5, 7], [2, 3, 4], [3, 7, 4]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractive = []\n",
    "for name in jsonArray:\n",
    "    extractive.append(name['extractive'])\n",
    "extractive[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "article_original = []\n",
    "for name in jsonArray:\n",
    "    article_original.append(name['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ha당 조사료 400만원…작물별 차등 지원'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_original[0][0][0]['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_article = []\n",
    "for i, article in enumerate(article_original):\n",
    "    article_sent = []\n",
    "    for j, art in enumerate(article):\n",
    "        article_text = []\n",
    "        for k, text in enumerate(art):\n",
    "            article_text.append(text['sentence'])\n",
    "        a_t = ','.join(article_text)\n",
    "        article_sent.append(a_t)\n",
    "    total_article.append(article_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ha당 조사료 400만원…작물별 차등 지원',\n",
       " '이성훈 sinawi@hanmail.net',\n",
       " '전라남도가 쌀 과잉문제를 근본적으로 해결하기 위해 올해부터 시행하는 쌀 생산조정제를 적극 추진키로 했다.',\n",
       " '쌀 생산조정제는 벼를 심었던 논에 벼 대신 사료작물이나 콩 등 다른 작물을 심으면 벼와의 일정 소득차를 보전해주는 제도다.',\n",
       " '올해 전남의 논 다른 작물 재배 계획면적은 전국 5만ha의 약 21%인 1만 698ha로, 세부시행지침을 확정, 시군에 통보했다.,지원사업 대상은 2017년산 쌀 변동직불금을 받은 농지에 10a(300평) 이상 벼 이외 다른 작물을 재배한 농업인이다.',\n",
       " '지원 대상 작물은 1년생을 포함한 다년생의 모든 작물이 해당되나 재배 면적 확대 시 수급과잉이 우려되는 고추, 무, 배추, 인삼, 대파 등 수급 불안 품목은 제외된다.',\n",
       " '농지의 경우도 이미 다른 작물 재배 의무가 부여된 간척지, 정부매입비축농지, 농진청 시범사업, 경관보전 직불금 수령 농지 등은 제외될 예정이다.',\n",
       " 'ha(3000평)당 지원 단가는 평균 340만원으로 사료작물 400만원, 일반작물은 340만원, 콩·팥 등 두류작물은 280만원 등이다.,벼와 소득차와 영농 편이성을 감안해 작물별로 차등 지원된다.',\n",
       " '논에 다른 작물 재배를 바라는 농가는 오는 22일부터 2월 28일까지 농지 소재지 읍면동사무소에 신청해야 한다.',\n",
       " '전남도는 도와 시군에 관련 기관과 농가 등이 참여하는‘논 타작물 지원사업 추진협의회’를 구성, 지역 특성에 맞는 작목 선정 및 사업 심의 등을 본격 추진할 방침이다.',\n",
       " '최향철 전라남도 친환경농업과장은 “최근 쌀값이 다소 상승추세에 있으나 매년 공급과잉에 따른 가격 하락으로 쌀농가에 어려움이 있었다”며“쌀 공급과잉을 구조적으로 해결하도록 논 타작물 재배 지원사업에 많이 참여해주길 바란다”고 말했다.']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_article[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['media'] = media\n",
    "df['id'] = id\n",
    "df['article_original'] = total_article\n",
    "df['article_morp'] = 0\n",
    "df['abstractive'] = abstractive\n",
    "df['extractive'] = extractive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media</th>\n",
       "      <th>id</th>\n",
       "      <th>article_original</th>\n",
       "      <th>article_morp</th>\n",
       "      <th>abstractive</th>\n",
       "      <th>extractive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>광양신문</td>\n",
       "      <td>290741778</td>\n",
       "      <td>[ha당 조사료 400만원…작물별 차등 지원, 이성훈 sinawi@hanmail.n...</td>\n",
       "      <td>0</td>\n",
       "      <td>전라남도가 쌀 과잉문제를 근본적으로 해결하기 위해 올해부터 벼를 심었던 논에 벼 대...</td>\n",
       "      <td>[2, 3, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>광양신문</td>\n",
       "      <td>290741792</td>\n",
       "      <td>[8억 투입, 고소천사벽화·자산마을에 색채 입혀, 이성훈 sinawi@hanmail...</td>\n",
       "      <td>0</td>\n",
       "      <td>여수시는 컬러빌리지 사업에 8억원을 투입하여 ‘색채와 빛’ 도시를 완성하여 고소천사...</td>\n",
       "      <td>[2, 4, 11]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  media         id                                   article_original  \\\n",
       "0  광양신문  290741778  [ha당 조사료 400만원…작물별 차등 지원, 이성훈 sinawi@hanmail.n...   \n",
       "1  광양신문  290741792  [8억 투입, 고소천사벽화·자산마을에 색채 입혀, 이성훈 sinawi@hanmail...   \n",
       "\n",
       "   article_morp                                        abstractive  extractive  \n",
       "0             0  전라남도가 쌀 과잉문제를 근본적으로 해결하기 위해 올해부터 벼를 심었던 논에 벼 대...  [2, 3, 10]  \n",
       "1             0  여수시는 컬러빌리지 사업에 8억원을 투입하여 ‘색채와 빛’ 도시를 완성하여 고소천사...  [2, 4, 11]  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- csv 파일 예시 <br>\n",
    "\n",
    "| media  | id       | article_original | article_morp      | abstractive | extractive |\n",
    "|:------:|:--------:|:----------------:|:-----------------:|:-----------:|:----------:|\n",
    "| 신문사 | 기사번호 | 기사원문         | 형태소분석된 기사 | 생성요약    | 추출요약   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(243983, 6)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "media               0\n",
       "id                  0\n",
       "article_original    0\n",
       "article_morp        0\n",
       "abstractive         0\n",
       "extractive          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text): \n",
    "    text = re.sub(r'(\\()(.*?)(\\))', '', str(text))  # 소괄호 (세부 설명)\n",
    "    text = re.sub(r'[가-힣]+ ([\\w\\.\\_\\-])*[a-zA-Z0-9]+([\\w\\.\\_\\-])*([a-zA-Z0-9])+([\\w\\.\\_\\-])+@([a-zA-Z0-9]+\\.)+[a-zA-Z0-9]{2,8}','',text) # 기자 이메일 제거\n",
    "    text = re.sub(r'\\'\\'','',text) # 공백 제거\n",
    "    text = re.sub(r'[?!]', '.', text)          # ?! => 마침표 처리\n",
    "    text = re.sub(r'[\\·\\:\\-\\_\\…]', ' ', text)  # 문장부호 구분자 => 공백 처리\n",
    "    text = re.sub(r'\\s+', ' ', text) #remove extra space\n",
    "    text = re.sub(r'^\\s+', '', text) #remove space from start\n",
    "    text = re.sub(r'\\s+$', '', text) #remove space from the end\n",
    "    text = re.sub('\\s{2,}', ' ', text)        # 2번 이상의 space 제거\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                        | 0/243983 [00:00<?, ?it/s]/var/folders/m6/hrff0b7x4hl1m5j8nxchlk5c0000gn/T/ipykernel_4436/2284716926.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['article_original'][i] = arr\n",
      "100%|██████████████████████████████████████████████████████████| 243983/243983 [09:06<00:00, 446.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    arr = []\n",
    "    for j in df['article_original'][i]:\n",
    "        arr.append(clean_text(j))\n",
    "    arr = [x for x in arr if x]\n",
    "    df['article_original'][i] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ha당 조사료 400만원 작물별 차등 지원',\n",
       " '전라남도가 쌀 과잉문제를 근본적으로 해결하기 위해 올해부터 시행하는 쌀 생산조정제를 적극 추진키로 했다.',\n",
       " '쌀 생산조정제는 벼를 심었던 논에 벼 대신 사료작물이나 콩 등 다른 작물을 심으면 벼와의 일정 소득차를 보전해주는 제도다.',\n",
       " '올해 전남의 논 다른 작물 재배 계획면적은 전국 5만ha의 약 21%인 1만 698ha로, 세부시행지침을 확정, 시군에 통보했다.,지원사업 대상은 2017년산 쌀 변동직불금을 받은 농지에 10a 이상 벼 이외 다른 작물을 재배한 농업인이다.',\n",
       " '지원 대상 작물은 1년생을 포함한 다년생의 모든 작물이 해당되나 재배 면적 확대 시 수급과잉이 우려되는 고추, 무, 배추, 인삼, 대파 등 수급 불안 품목은 제외된다.',\n",
       " '농지의 경우도 이미 다른 작물 재배 의무가 부여된 간척지, 정부매입비축농지, 농진청 시범사업, 경관보전 직불금 수령 농지 등은 제외될 예정이다.',\n",
       " 'ha당 지원 단가는 평균 340만원으로 사료작물 400만원, 일반작물은 340만원, 콩 팥 등 두류작물은 280만원 등이다.,벼와 소득차와 영농 편이성을 감안해 작물별로 차등 지원된다.',\n",
       " '논에 다른 작물 재배를 바라는 농가는 오는 22일부터 2월 28일까지 농지 소재지 읍면동사무소에 신청해야 한다.',\n",
       " '전남도는 도와 시군에 관련 기관과 농가 등이 참여하는‘논 타작물 지원사업 추진협의회’를 구성, 지역 특성에 맞는 작목 선정 및 사업 심의 등을 본격 추진할 방침이다.',\n",
       " '최향철 전라남도 친환경농업과장은 “최근 쌀값이 다소 상승추세에 있으나 매년 공급과잉에 따른 가격 하락으로 쌀농가에 어려움이 있었다”며“쌀 공급과잉을 구조적으로 해결하도록 논 타작물 재배 지원사업에 많이 참여해주길 바란다”고 말했다.']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['article_original'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['전라남도',\n",
       " '가',\n",
       " '쌀',\n",
       " '과잉',\n",
       " '문제',\n",
       " '를',\n",
       " '근본',\n",
       " '적',\n",
       " '으로',\n",
       " '해결',\n",
       " '하',\n",
       " '기',\n",
       " '위해',\n",
       " '올해',\n",
       " '부터',\n",
       " '시행',\n",
       " '하',\n",
       " '는',\n",
       " '쌀',\n",
       " '생산',\n",
       " '조정',\n",
       " '제',\n",
       " '를',\n",
       " '적극',\n",
       " '추진',\n",
       " '키로',\n",
       " '했',\n",
       " '다',\n",
       " '.']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "mecab = Mecab()\n",
    "# 형태소 분석\n",
    "mecab.morphs('전라남도가 쌀 과잉문제를 근본적으로 해결하기 위해 올해부터 시행하는 쌀 생산조정제를 적극 추진키로 했다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                        | 0/243983 [00:00<?, ?it/s]/var/folders/m6/hrff0b7x4hl1m5j8nxchlk5c0000gn/T/ipykernel_4436/4120418180.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['article_morp'][i] = arr\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/imok/lib/python3.9/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "100%|█████████████████████████████████████████████████████████| 243983/243983 [03:21<00:00, 1210.22it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(df))):\n",
    "    arr = []\n",
    "    for j in df['article_original'][i]:\n",
    "        arr.append(' '.join(mecab.morphs(j)))\n",
    "    df['article_morp'][i] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ha 당 조사료 400 만 원 작물 별 차등 지원',\n",
       " '전라남도 가 쌀 과잉 문제 를 근본 적 으로 해결 하 기 위해 올해 부터 시행 하 는 쌀 생산 조정 제 를 적극 추진 키로 했 다 .',\n",
       " '쌀 생산 조정 제 는 벼 를 심 었 던 논 에 벼 대신 사료 작물 이나 콩 등 다른 작물 을 심 으면 벼 와 의 일정 소득 차 를 보전 해 주 는 제도 다 .',\n",
       " '올해 전남 의 논 다른 작물 재배 계획 면적 은 전국 5 만 ha 의 약 21 % 인 1 만 698 ha 로 , 세부 시행 지침 을 확정 , 시군 에 통보 했 다 . , 지원 사업 대상 은 2017 년 산 쌀 변동 직 불금 을 받 은 농지 에 10 a 이상 벼 이외 다른 작물 을 재배 한 농업 인 이 다 .',\n",
       " '지원 대상 작물 은 1 년 생 을 포함 한 다년생 의 모든 작물 이 해당 되 나 재배 면적 확대 시 수급 과잉 이 우려 되 는 고추 , 무 , 배추 , 인삼 , 대파 등 수급 불안 품목 은 제외 된다 .',\n",
       " '농지 의 경우 도 이미 다른 작물 재배 의무 가 부여 된 간척지 , 정부 매입 비축 농지 , 농진청 시범 사업 , 경관 보전 직 불금 수령 농지 등 은 제외 될 예정 이 다 .',\n",
       " 'ha 당 지원 단가 는 평균 340 만 원 으로 사료 작물 400 만 원 , 일반 작물 은 340 만 원 , 콩 팥 등 두류 작물 은 280 만 원 등 이 다 . , 벼 와 소득 차 와 영농 편이 성 을 감안 해 작물 별 로 차등 지원 된다 .',\n",
       " '논 에 다른 작물 재배 를 바라 는 농가 는 오 는 22 일 부터 2 월 28 일 까지 농지 소재지 읍 면 동사무소 에 신청 해야 한다 .',\n",
       " '전남 도 는 도와 시군 에 관련 기관 과 농가 등 이 참여 하 는 ‘ 논 타 작물 지원 사업 추진 협의회 ’ 를 구성 , 지역 특성 에 맞 는 작목 선정 및 사업 심의 등 을 본격 추진 할 방침 이 다 .',\n",
       " '최향 철 전라남도 친환경 농업 과장 은 “ 최근 쌀값 이 다소 상승 추세 에 있 으나 매년 공급 과잉 에 따른 가격 하락 으로 쌀 농가 에 어려움 이 있 었 다 ” 며 “ 쌀 공급 과잉 을 구조 적 으로 해결 하 도록 논 타 작물 재배 지원 사업 에 많이 참여 해 주 길 바란다 ” 고 말 했 다 .']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.article_morp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"전라남도가 쌀 과잉문제를 근본적으로 해결하기 위해 올해부터 벼를 심었던 논에 벼 대신 사료작물이나 콩 등 다른 작물을 심으면 벼와의 일정 소득차를 보전해주는 '쌀 생산조정제'를 적극적으로 시행하기로 하고 오는 22일부터 2월 28일까지 농지 소재지 읍면동사무소에서 신청받는다 .\""
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.abstractive[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ha당 조사료 400만원 작물별 차등 지원',\n",
       " '전라남도가 쌀 과잉문제를 근본적으로 해결하기 위해 올해부터 시행하는 쌀 생산조정제를 적극 추진키로 했다.',\n",
       " '쌀 생산조정제는 벼를 심었던 논에 벼 대신 사료작물이나 콩 등 다른 작물을 심으면 벼와의 일정 소득차를 보전해주는 제도다.',\n",
       " '올해 전남의 논 다른 작물 재배 계획면적은 전국 5만ha의 약 21%인 1만 698ha로, 세부시행지침을 확정, 시군에 통보했다.,지원사업 대상은 2017년산 쌀 변동직불금을 받은 농지에 10a 이상 벼 이외 다른 작물을 재배한 농업인이다.',\n",
       " '지원 대상 작물은 1년생을 포함한 다년생의 모든 작물이 해당되나 재배 면적 확대 시 수급과잉이 우려되는 고추, 무, 배추, 인삼, 대파 등 수급 불안 품목은 제외된다.',\n",
       " '농지의 경우도 이미 다른 작물 재배 의무가 부여된 간척지, 정부매입비축농지, 농진청 시범사업, 경관보전 직불금 수령 농지 등은 제외될 예정이다.',\n",
       " 'ha당 지원 단가는 평균 340만원으로 사료작물 400만원, 일반작물은 340만원, 콩 팥 등 두류작물은 280만원 등이다.,벼와 소득차와 영농 편이성을 감안해 작물별로 차등 지원된다.',\n",
       " '논에 다른 작물 재배를 바라는 농가는 오는 22일부터 2월 28일까지 농지 소재지 읍면동사무소에 신청해야 한다.',\n",
       " '전남도는 도와 시군에 관련 기관과 농가 등이 참여하는‘논 타작물 지원사업 추진협의회’를 구성, 지역 특성에 맞는 작목 선정 및 사업 심의 등을 본격 추진할 방침이다.',\n",
       " '최향철 전라남도 친환경농업과장은 “최근 쌀값이 다소 상승추세에 있으나 매년 공급과잉에 따른 가격 하락으로 쌀농가에 어려움이 있었다”며“쌀 공급과잉을 구조적으로 해결하도록 논 타작물 재배 지원사업에 많이 참여해주길 바란다”고 말했다.']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.article_original[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv로 저장\n",
    "df.to_csv('/Users/imok/workspace/github/imOk/AI/train_result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 신문 train 데이터 csv to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media</th>\n",
       "      <th>id</th>\n",
       "      <th>article_original</th>\n",
       "      <th>article_morp</th>\n",
       "      <th>abstractive</th>\n",
       "      <th>extractive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>광양신문</td>\n",
       "      <td>290741778</td>\n",
       "      <td>['ha당 조사료 400만원 작물별 차등 지원', '전라남도가 쌀 과잉문제를 근본적...</td>\n",
       "      <td>['ha 당 조사료 400 만 원 작물 별 차등 지원', '전라남도 가 쌀 과잉 문...</td>\n",
       "      <td>전라남도가 쌀 과잉문제를 근본적으로 해결하기 위해 올해부터 벼를 심었던 논에 벼 대...</td>\n",
       "      <td>[2, 3, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>광양신문</td>\n",
       "      <td>290741792</td>\n",
       "      <td>['8억 투입, 고소천사벽화 자산마을에 색채 입혀', '여수시는 원도심 일대에서 추...</td>\n",
       "      <td>['8 억 투 입 , 고소 천사 벽화 자산 마을 에 색채 입혀', '여수시 는 원 ...</td>\n",
       "      <td>여수시는 컬러빌리지 사업에 8억원을 투입하여 ‘색채와 빛’ 도시를 완성하여 고소천사...</td>\n",
       "      <td>[2, 4, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>광양신문</td>\n",
       "      <td>290741793</td>\n",
       "      <td>['전남드래곤즈 해맞이 다짐 선수 영입 활발', '전남드래곤즈는 지난 4일 구봉산 ...</td>\n",
       "      <td>['전남 드래곤즈 해맞이 다짐 선수 영입 활발', '전남 드래곤즈 는 지난 4 일 ...</td>\n",
       "      <td>전남드래곤즈 임직원과 선수단이 4일 구봉산 정상에 올라 일출을 보며 2018년 구단...</td>\n",
       "      <td>[3, 5, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>광양신문</td>\n",
       "      <td>290741794</td>\n",
       "      <td>['11~24일, 매실 감 참다래 등 지역특화작목', '광양시는 오는 11일부터 2...</td>\n",
       "      <td>['11 ~ 24 일 , 매실 감 참 다래 등 지역 특화 작목', '광양시 는 오 ...</td>\n",
       "      <td>광양시는 농업인들의 경쟁력을 높이고, 소득안정을 위해 매실·감·참다래 등 지역특화작...</td>\n",
       "      <td>[2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>광양신문</td>\n",
       "      <td>290741797</td>\n",
       "      <td>['홍콩 크루즈선사‘아쿠아리우스’ 4, 6월 여수항 입항', '타이완의 크루즈관광객...</td>\n",
       "      <td>['홍콩 크루즈 선사 ‘ 아쿠아 리우스 ’ 4 , 6 월 여수항 입항', '타이완 ...</td>\n",
       "      <td>올해 4월과 6월 두 차례에 걸쳐 타이완의 크루즈 관광객 4000여명이 여수에 입항...</td>\n",
       "      <td>[3, 7, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  media         id                                   article_original  \\\n",
       "0  광양신문  290741778  ['ha당 조사료 400만원 작물별 차등 지원', '전라남도가 쌀 과잉문제를 근본적...   \n",
       "1  광양신문  290741792  ['8억 투입, 고소천사벽화 자산마을에 색채 입혀', '여수시는 원도심 일대에서 추...   \n",
       "2  광양신문  290741793  ['전남드래곤즈 해맞이 다짐 선수 영입 활발', '전남드래곤즈는 지난 4일 구봉산 ...   \n",
       "3  광양신문  290741794  ['11~24일, 매실 감 참다래 등 지역특화작목', '광양시는 오는 11일부터 2...   \n",
       "4  광양신문  290741797  ['홍콩 크루즈선사‘아쿠아리우스’ 4, 6월 여수항 입항', '타이완의 크루즈관광객...   \n",
       "\n",
       "                                        article_morp  \\\n",
       "0  ['ha 당 조사료 400 만 원 작물 별 차등 지원', '전라남도 가 쌀 과잉 문...   \n",
       "1  ['8 억 투 입 , 고소 천사 벽화 자산 마을 에 색채 입혀', '여수시 는 원 ...   \n",
       "2  ['전남 드래곤즈 해맞이 다짐 선수 영입 활발', '전남 드래곤즈 는 지난 4 일 ...   \n",
       "3  ['11 ~ 24 일 , 매실 감 참 다래 등 지역 특화 작목', '광양시 는 오 ...   \n",
       "4  ['홍콩 크루즈 선사 ‘ 아쿠아 리우스 ’ 4 , 6 월 여수항 입항', '타이완 ...   \n",
       "\n",
       "                                         abstractive  extractive  \n",
       "0  전라남도가 쌀 과잉문제를 근본적으로 해결하기 위해 올해부터 벼를 심었던 논에 벼 대...  [2, 3, 10]  \n",
       "1  여수시는 컬러빌리지 사업에 8억원을 투입하여 ‘색채와 빛’ 도시를 완성하여 고소천사...  [2, 4, 11]  \n",
       "2  전남드래곤즈 임직원과 선수단이 4일 구봉산 정상에 올라 일출을 보며 2018년 구단...   [3, 5, 7]  \n",
       "3  광양시는 농업인들의 경쟁력을 높이고, 소득안정을 위해 매실·감·참다래 등 지역특화작...   [2, 3, 4]  \n",
       "4  올해 4월과 6월 두 차례에 걸쳐 타이완의 크루즈 관광객 4000여명이 여수에 입항...   [3, 7, 4]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('/Users/imok/workspace/github/imOk/AI/train_result.csv').drop('Unnamed: 0', axis=1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(test, test_size = 0.2)\n",
    "valid_set, test_set = train_test_split(test_set, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 195186/195186 [00:37<00:00, 5219.11it/s]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "list_dic = []\n",
    "for idx, row in train_set.iterrows():\n",
    "    raw = row['article_morp']\n",
    "    target_idx = ast.literal_eval(row['extractive'])\n",
    "\n",
    "    sentences = raw.split(',')\n",
    "    src = [i.split(' ') for i in sentences]\n",
    "    tgt = [a for i,a in enumerate(src) if i in target_idx]\n",
    "  \n",
    "    mydict = {}\n",
    "    mydict['src'] = src\n",
    "    mydict['tgt'] = tgt\n",
    "    list_dic.append(mydict)\n",
    "        \n",
    "temp = []\n",
    "for i,a in enumerate(tqdm(list_dic)):\n",
    "    if (i+1)%6!=0:\n",
    "        temp.append(a)\n",
    "    else:\n",
    "        filename = 'korean.'+'train'+'.'+str(i//6)+'.json'\n",
    "        with open('/Users/imok/workspace/github/imOk/AI/KorBertSum'+'/json_data/'+filename, \"w\", encoding='utf-8') as json_file:\n",
    "            json.dump(temp, json_file, ensure_ascii=False)\n",
    "        temp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 43917/43917 [00:07<00:00, 5637.73it/s]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir('/Users/imok/workspace/github/imOk/AI/KorBertSum/json_data/val')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "list_dic = []\n",
    "for idx, row in valid_set.iterrows():\n",
    "    raw = row['article_morp']\n",
    "    target_idx = ast.literal_eval(row['extractive'])\n",
    "\n",
    "    sentences = raw.split(',')\n",
    "    src = [i.split(' ') for i in sentences]\n",
    "    tgt = [a for i,a in enumerate(src) if i in target_idx]\n",
    "\n",
    "    mydict = {}\n",
    "    mydict['src'] = src\n",
    "    mydict['tgt'] = tgt\n",
    "    list_dic.append(mydict)\n",
    "        \n",
    "temp = []\n",
    "for i,a in enumerate(tqdm(list_dic)):\n",
    "    \n",
    "    if (i+1)%6!=0:\n",
    "        temp.append(a)\n",
    "    else:\n",
    "        filename = 'korean.'+'valid'+'.'+str(i//6)+'.json'\n",
    "        with open('/Users/imok/workspace/github/imOk/AI/KorBertSum'+'/json_data/val/'+filename, \"w\", encoding='utf-8') as json_file:\n",
    "            json.dump(temp, json_file, ensure_ascii=False)\n",
    "        temp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 43917/43917 [00:07<00:00, 5679.96it/s]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir('/Users/imok/workspace/github/imOk/AI/KorBertSum/json_data/test')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "list_dic = []\n",
    "for idx, row in valid_set.iterrows():\n",
    "    raw = row['article_morp']\n",
    "    target_idx = ast.literal_eval(row['extractive'])\n",
    "\n",
    "    sentences = raw.split(',')\n",
    "    src = [i.split(' ') for i in sentences]\n",
    "    tgt = [a for i,a in enumerate(src) if i in target_idx]\n",
    "\n",
    "    mydict = {}\n",
    "    mydict['src'] = src\n",
    "    mydict['tgt'] = tgt\n",
    "    list_dic.append(mydict)\n",
    "        \n",
    "temp = []\n",
    "for i,a in enumerate(tqdm(list_dic)):\n",
    "    \n",
    "    if (i+1)%6!=0:\n",
    "        temp.append(a)\n",
    "    else:\n",
    "        filename = 'korean.'+'test'+'.'+str(i//6)+'.json'\n",
    "        with open('/Users/imok/workspace/github/imOk/AI/KorBertSum'+'/json_data/test/'+filename, \"w\", encoding='utf-8') as json_file:\n",
    "            json.dump(temp, json_file, ensure_ascii=False)\n",
    "        temp = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-_ts9gJjeD5"
   },
   "source": [
    "### (4) 신문 train 데이터 json to pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 491,
     "status": "ok",
     "timestamp": 1649935167632,
     "user": {
      "displayName": "ImOk",
      "userId": "13644748134003701721"
     },
     "user_tz": -540
    },
    "id": "xbVRcS_QjeD6",
    "outputId": "fc2dc12a-a924-458e-8cd9-ac12bfb65237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/imok/workspace/github/imOk/AI/KorBertSum/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 520,
     "status": "ok",
     "timestamp": 1649936696969,
     "user": {
      "displayName": "ImOk",
      "userId": "13644748134003701721"
     },
     "user_tz": -540
    },
    "id": "rvplIGWjsg-q",
    "outputId": "105f7788-cca5-48fc-eef5-5e3e6a33b329"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/imok/workspace/github/imOk/AI/KorBertSum/src\n"
     ]
    }
   ],
   "source": [
    "cd /Users/imok/workspace/github/imOk/AI/KorBertSum/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QOG7zA-XjeD6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%time\n",
    "!python preprocess.py \\\n",
    "-mode format_to_bert \\\n",
    "-raw_path ../json_data \\\n",
    "-save_path ../bert_data \\\n",
    "-dataset train \\\n",
    "-vocab_file_path ../../model/001_bert_morp_pytorch/vocab.korean_morp.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "output_embedded_package_id": "184xcow5fwbKY-yf8WpbWVf-lphOH7md_"
    },
    "executionInfo": {
     "elapsed": 700027,
     "status": "ok",
     "timestamp": 1649937472517,
     "user": {
      "displayName": "ImOk",
      "userId": "13644748134003701721"
     },
     "user_tz": -540
    },
    "id": "es-TPf30jeD7",
    "outputId": "d6c35c92-8c25-4060-c1dc-8e646d311515",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('/Users/imok/workspace/github/imOk/AI/KorBertSum/bert_data/val')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "!python preprocess.py \\\n",
    "-mode format_to_bert \\\n",
    "-raw_path ../json_data/val \\\n",
    "-save_path ../bert_data \\\n",
    "-dataset valid \\\n",
    "-vocab_file_path ../../model/001_bert_morp_pytorch/vocab.korean_morp.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "output_embedded_package_id": "1TTONWR0ktSCLTEc9ue2ORyjgu_6_k5lC"
    },
    "executionInfo": {
     "elapsed": 705156,
     "status": "ok",
     "timestamp": 1649938178964,
     "user": {
      "displayName": "ImOk",
      "userId": "13644748134003701721"
     },
     "user_tz": -540
    },
    "id": "6afvE3XbjeD7",
    "outputId": "c5210b24-4db1-4693-b834-ceaec2712935",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('/Users/imok/workspace/github/imOk/AI/KorBertSum/bert_data/test')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "!python preprocess.py \\\n",
    "-mode format_to_bert \\\n",
    "-raw_path ../json_data/test \\\n",
    "-save_path ../bert_data \\\n",
    "-dataset test \\\n",
    "-vocab_file_path ../../model/001_bert_morp_pytorch/vocab.korean_morp.list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wy7dbwcgjeD7"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMy5ZSv2jeD7"
   },
   "source": [
    "## 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 626,
     "status": "ok",
     "timestamp": 1649953469468,
     "user": {
      "displayName": "ImOk",
      "userId": "13644748134003701721"
     },
     "user_tz": -540
    },
    "id": "nqkX_O7ruuXE",
    "outputId": "fdc30636-d20a-4a99-88e0-ecdd9ad91580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/imok/workspace/github/imOk/AI\n"
     ]
    }
   ],
   "source": [
    "cd /Users/imok/workspace/github/imOk/AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZyk3o_1jeD7"
   },
   "source": [
    "### (1) package 설치 및 colab GPU 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 21781,
     "status": "ok",
     "timestamp": 1649953492968,
     "user": {
      "displayName": "ImOk",
      "userId": "13644748134003701721"
     },
     "user_tz": -540
    },
    "id": "s-WZxapYi7gE",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "8c0f5a13-e658-4184-aee6-c07c360e9f5b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_pretrained_bert\n",
      "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 8.9 MB/s \n",
      "\u001b[?25hCollecting boto3\n",
      "  Downloading boto3-1.21.40-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 53.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.10.0+cu111)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.21.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.64.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.1.1)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
      "Collecting botocore<1.25.0,>=1.24.40\n",
      "  Downloading botocore-1.24.40-py3-none-any.whl (8.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.7 MB 54.0 MB/s \n",
      "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 9.8 MB/s \n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 29.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.40->boto3->pytorch_pretrained_bert) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.40->boto3->pytorch_pretrained_bert) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 73.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
      "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Successfully installed boto3-1.21.40 botocore-1.24.40 jmespath-1.0.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.5.2 urllib3-1.25.11\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[K     |████████████████████████████████| 125 kB 8.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.15.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.5)\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-2.5\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 9.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 45.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 8.1 MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 54.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 65.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n",
      "Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (1.9)\n"
     ]
    }
   ],
   "source": [
    "# 기타 패키지 설치\n",
    "!pip install pytorch_pretrained_bert\n",
    "!pip install tensorboardX\n",
    "!pip install transformers\n",
    "!pip install easydict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTVweUKMjeD7"
   },
   "source": [
    "#### pyrouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73764,
     "status": "ok",
     "timestamp": 1649953566721,
     "user": {
      "displayName": "ImOk",
      "userId": "13644748134003701721"
     },
     "user_tz": -540
    },
    "id": "EVpTRp5bhlPs",
    "outputId": "3c2cd0fa-7645-4b77-db88-9d1101ddcd6c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install bheinzerling's pyrouge\n",
    "!git clone https://github.com/bheinzerling/pyrouge\n",
    "%cd pyrouge\n",
    "!python setup.py install\n",
    "# install missing dependency\n",
    "!apt install libxml-parser-perl\n",
    "%cd pyrouge\n",
    "!git clone https://github.com/andersjo/pyrouge.git rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2608,
     "status": "ok",
     "timestamp": 1649953569323,
     "user": {
      "displayName": "ImOk",
      "userId": "13644748134003701721"
     },
     "user_tz": -540
    },
    "id": "jqhwqzKqi3p2",
    "outputId": "295d96dc-edca-4c44-9e34-0d2f2a9bf308"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-15 12:29:28,173 [MainThread  ] [INFO ]  Set ROUGE home directory to /Users/imok/workspace/github/imOk/AI/pyrouge/pyrouge/rouge/tools/ROUGE-1.5.5.\n",
      "/Users/imok/workspace/github/imOk/AI/pyrouge/pyrouge/rouge/tools/ROUGE-1.5.5/data\n"
     ]
    }
   ],
   "source": [
    "!pyrouge_set_rouge_path '/Users/imok/workspace/github/imOk/AI/pyrouge/pyrouge/rouge/tools/ROUGE-1.5.5'\n",
    "%cd /Users/imok/workspace/github/imOk/AI/pyrouge/pyrouge/rouge/tools/ROUGE-1.5.5/data\n",
    "!mv WordNet-2.0.exc.db WordNet-2.0.exc.db.orig\n",
    "!perl WordNet-2.0-Exceptions/buildExeptionDB.pl ./WordNet-2.0-Exceptions ./smart_common_words.txt ./WordNet-2.0.exc.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8c0aO9ubmg5c"
   },
   "source": [
    "- colab에서 1분마다 자동 재연결\n",
    "- 개발자 console에서 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDxLwUmevrJ4"
   },
   "source": [
    "```\n",
    "function ClickConnect() {\n",
    "    var buttons = document.querySelectorAll(\"colab-dialog.yes-no-dialog paper-button#cancel\"); \n",
    "    buttons.forEach(function(btn) { \n",
    "        btn.click(); \n",
    "    }); \n",
    "    console.log(\"1분마다 자동 재연결\"); \n",
    "    document.querySelector(\"colab-toolbar-button#connect\").click(); \n",
    "} \n",
    "setInterval(ClickConnect,1000*60);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9jTKJ5hqGro"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wa5vcawrGlbo",
    "tags": []
   },
   "source": [
    "### (2) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1649953577094,
     "user": {
      "displayName": "ImOk",
      "userId": "13644748134003701721"
     },
     "user_tz": -540
    },
    "id": "37I0mfo2vIba",
    "outputId": "ed07a93b-0d5f-4029-f0b1-a7c6a66875ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/imok/workspace/github/imOk/AI/pyrouge/pyrouge/rouge/tools/ROUGE-1.5.5/data\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1649953579120,
     "user": {
      "displayName": "ImOk",
      "userId": "13644748134003701721"
     },
     "user_tz": -540
    },
    "id": "ikdiLJ7ujnPP",
    "outputId": "2a49608a-38c6-4222-f22d-8a4db48ba3c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/imok/workspace/github/imOk/AI/pyrouge/pyrouge/rouge/tools/ROUGE-1.5.5\n"
     ]
    }
   ],
   "source": [
    "cd /Users/imok/workspace/github/imOk/AI/pyrouge/pyrouge/rouge/tools/ROUGE-1.5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1649953579410,
     "user": {
      "displayName": "ImOk",
      "userId": "13644748134003701721"
     },
     "user_tz": -540
    },
    "id": "GtWER2NLjq38",
    "outputId": "1148ef44-536b-4db4-bf08-b7aa2b393892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.txt        \u001b[31mROUGE-1.5.5.pl\u001b[m\u001b[m*   \u001b[1m\u001b[36mdata\u001b[m\u001b[m/\n",
      "RELEASE-NOTE.txt  \u001b[1m\u001b[36mXML\u001b[m\u001b[m/              \u001b[31mrunROUGE-test.pl\u001b[m\u001b[m*\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1649953583176,
     "user": {
      "displayName": "ImOk",
      "userId": "13644748134003701721"
     },
     "user_tz": -540
    },
    "id": "Yo2i7IwDjmHM"
   },
   "outputs": [],
   "source": [
    "# PermissionError: [Errno 13] Permission denied: '/content/drive/MyDrive/AI/pyrouge/pyrouge/rouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl'\n",
    "!chmod 777 ROUGE-1.5.5.pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 455,
     "status": "ok",
     "timestamp": 1649953585551,
     "user": {
      "displayName": "ImOk",
      "userId": "13644748134003701721"
     },
     "user_tz": -540
    },
    "id": "tkVO9XGlz19Y",
    "outputId": "0f5a19c4-c1b0-471e-9e97-6c199a4e8e60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/imok/workspace/github/imOk/AI/KorBertSum/src\n"
     ]
    }
   ],
   "source": [
    "cd /Users/imok/workspace/github/imOk/AI/KorBertSum/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pzASkXjjbeg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# m1 pytorch 에서 GPU 사용 불가\n",
    "# AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'\n",
    "!python train.py -mode train -encoder classifier -dropout 0.1 \\\n",
    "-bert_data_path /Users/imok/workspace/github/imOk/AI/KorBertSum/bert_data/korean \\\n",
    "-model_path ../models/bert_classifier \\\n",
    "-lr 2e-3 -visible_gpus -1 -gpu_ranks -1 -world_size 1 -report_every 50 -save_checkpoint_steps 1000 \\\n",
    "-batch_size 1000 -decay_method noam -train_steps 1000 -accum_count 1 \\\n",
    "-log_file ../logs/bert_classifier -use_interval true -warmup_steps 8000 \\\n",
    "-bert_model /Users/imok/workspace/github/imOk/AI/model/001_bert_morp_pytorch \\\n",
    "-bert_config_path /Users/imok/workspace/github/imOk/AI/model/001_bert_morp_pytorch/bert_config.json -temp_dir ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWd-qpB_GoeE"
   },
   "source": [
    "### (3) Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "7XV4tywmcT_P",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "d78110a4-5f82-43bc-a267-ce5e1bbd4cb8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-04-14 15:13:09,542 INFO] Loading checkpoint from ../models/bert_classifier/model_step_1000.pt\n",
      "Namespace(accum_count=1, batch_size=1000, bert_config_path='/content/drive/MyDrive/AI/model/001_bert_morp_pytorch/bert_config.json', bert_data_path='/content/drive/MyDrive/AI/KorBertSum/bert_data/eunok/korean', bert_model='/content/drive/MyDrive/AI/model/001_bert_morp_pytorch', beta1=0.9, beta2=0.999, block_trigram=True, dataset='', decay_method='noam', dropout=0.1, encoder='classifier', ff_size=512, gpu_ranks=[0], heads=4, hidden_size=128, inter_layers=2, log_file='../logs/bert_classifier', lr=0.002, max_grad_norm=0, mode='validate', model_path='../models/bert_classifier', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=50, report_rouge=True, result_path='../results/korean', rnn_size=512, save_checkpoint_steps=1000, seed=666, temp_dir='.', test_all=False, test_from='', train_from='', train_steps=1000, use_interval=True, visible_gpus='0', warmup_steps=8000, world_size=1)\n",
      "[2022-04-14 15:13:11,449 INFO] loading archive file /content/drive/MyDrive/AI/model/001_bert_morp_pytorch\n",
      "[2022-04-14 15:13:11,450 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-14 15:13:17,766 INFO] Loading valid dataset from /content/drive/MyDrive/AI/KorBertSum/bert_data/eunok/korean.valid.0.bert.pt\n",
      "[2022-04-14 15:13:17,770 INFO] Loaded valid dataset from /content/drive/MyDrive/AI/KorBertSum/bert_data/eunok/korean.valid.0.bert.pt, number of examples: 5\n",
      "gpu_rank 0\n",
      "[2022-04-14 15:13:17,777 INFO] * number of parameters: 109350145\n",
      "[2022-04-14 15:13:18,165 INFO] Validation xent: 5.7927 at step 1000\n",
      "[2022-04-14 15:13:18,226 INFO] Loading checkpoint from ../models/bert_classifier/model_step_1000.pt\n",
      "Namespace(accum_count=1, batch_size=1000, bert_config_path='/content/drive/MyDrive/AI/model/001_bert_morp_pytorch/bert_config.json', bert_data_path='/content/drive/MyDrive/AI/KorBertSum/bert_data/eunok/korean', bert_model='/content/drive/MyDrive/AI/model/001_bert_morp_pytorch', beta1=0.9, beta2=0.999, block_trigram=True, dataset='', decay_method='noam', dropout=0.1, encoder='classifier', ff_size=512, gpu_ranks=[0], heads=4, hidden_size=128, inter_layers=2, log_file='../logs/bert_classifier', lr=0.002, max_grad_norm=0, mode='validate', model_path='../models/bert_classifier', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=50, report_rouge=True, result_path='../results/korean', rnn_size=512, save_checkpoint_steps=1000, seed=666, temp_dir='.', test_all=False, test_from='', train_from='', train_steps=1000, use_interval=True, visible_gpus='0', warmup_steps=8000, world_size=1)\n",
      "[2022-04-14 15:13:19,729 INFO] loading archive file /content/drive/MyDrive/AI/model/001_bert_morp_pytorch\n",
      "[2022-04-14 15:13:19,731 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-14 15:13:21,890 INFO] Loading test dataset from /content/drive/MyDrive/AI/KorBertSum/bert_data/eunok/korean.test.7318.bert.pt\n",
      "[2022-04-14 15:13:21,893 INFO] Loaded test dataset from /content/drive/MyDrive/AI/KorBertSum/bert_data/eunok/korean.test.7318.bert.pt, number of examples: 5\n",
      "gpu_rank 0\n",
      "[2022-04-14 15:13:21,942 INFO] * number of parameters: 109350145\n",
      "5\n",
      "5\n",
      "2022-04-14 15:13:22,363 [MainThread  ] [INFO ]  Writing summaries.\n",
      "[2022-04-14 15:13:22,363 INFO] Writing summaries.\n",
      "2022-04-14 15:13:22,368 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ./tmpd9gvq0g1/system and model files to ./tmpd9gvq0g1/model.\n",
      "[2022-04-14 15:13:22,368 INFO] Processing summaries. Saving system files to ./tmpd9gvq0g1/system and model files to ./tmpd9gvq0g1/model.\n",
      "2022-04-14 15:13:22,369 [MainThread  ] [INFO ]  Processing files in ./rouge-tmp-2022-04-14-15-13-22/candidate/.\n",
      "[2022-04-14 15:13:22,369 INFO] Processing files in ./rouge-tmp-2022-04-14-15-13-22/candidate/.\n",
      "2022-04-14 15:13:22,397 [MainThread  ] [INFO ]  Saved processed files to ./tmpd9gvq0g1/system.\n",
      "[2022-04-14 15:13:22,397 INFO] Saved processed files to ./tmpd9gvq0g1/system.\n",
      "2022-04-14 15:13:22,398 [MainThread  ] [INFO ]  Processing files in ./rouge-tmp-2022-04-14-15-13-22/reference/.\n",
      "[2022-04-14 15:13:22,398 INFO] Processing files in ./rouge-tmp-2022-04-14-15-13-22/reference/.\n",
      "2022-04-14 15:13:22,437 [MainThread  ] [INFO ]  Saved processed files to ./tmpd9gvq0g1/model.\n",
      "[2022-04-14 15:13:22,437 INFO] Saved processed files to ./tmpd9gvq0g1/model.\n",
      "2022-04-14 15:13:22,443 [MainThread  ] [INFO ]  Written ROUGE configuration to ./tmpc10cfbbl/rouge_conf.xml\n",
      "[2022-04-14 15:13:22,443 INFO] Written ROUGE configuration to ./tmpc10cfbbl/rouge_conf.xml\n",
      "2022-04-14 15:13:22,443 [MainThread  ] [INFO ]  Running ROUGE with command /content/drive/MyDrive/AI/pyrouge/pyrouge/rouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/MyDrive/AI/pyrouge/pyrouge/rouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./tmpc10cfbbl/rouge_conf.xml\n",
      "[2022-04-14 15:13:22,443 INFO] Running ROUGE with command /content/drive/MyDrive/AI/pyrouge/pyrouge/rouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/MyDrive/AI/pyrouge/pyrouge/rouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./tmpc10cfbbl/rouge_conf.xml\n",
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.92168 (95%-conf.int. 0.76000 - 1.00000)\n",
      "1 ROUGE-1 Average_P: 0.83337 (95%-conf.int. 0.71667 - 0.95000)\n",
      "1 ROUGE-1 Average_F: 0.86556 (95%-conf.int. 0.75810 - 0.97143)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.45235 (95%-conf.int. 0.05000 - 0.85000)\n",
      "1 ROUGE-2 Average_P: 0.32073 (95%-conf.int. 0.06667 - 0.57333)\n",
      "1 ROUGE-2 Average_F: 0.36856 (95%-conf.int. 0.05714 - 0.67714)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.92168 (95%-conf.int. 0.76000 - 1.00000)\n",
      "1 ROUGE-L Average_P: 0.83337 (95%-conf.int. 0.71667 - 0.95000)\n",
      "1 ROUGE-L Average_F: 0.86556 (95%-conf.int. 0.75810 - 0.97143)\n",
      "\n",
      "[2022-04-14 15:13:24,935 INFO] Rouges at step 1000 \n",
      ">> ROUGE-F(1/2/3/l): 86.56/36.86/86.56\n",
      "ROUGE-R(1/2/3/l): 92.17/45.23/92.17\n",
      "\n",
      "[2022-04-14 15:13:24,936 INFO] Validation xent: 3.38433 at step 1000\n"
     ]
    }
   ],
   "source": [
    "!python train.py -mode validate -encoder classifier -dropout 0.1 \\\n",
    "-bert_data_path /Users/imok/workspace/github/imOk/AI/KorBertSum/bert_data/korean \\\n",
    "-model_path ../models/bert_classifier \\\n",
    "-lr 2e-3 -visible_gpus 0 -gpu_ranks 0 -world_size 1 -report_every 50 -save_checkpoint_steps 1000 \\\n",
    "-batch_size 1000 -decay_method noam -train_steps 1000 -accum_count 1 \\\n",
    "-log_file ../logs/bert_classifier -use_interval true -warmup_steps 8000 \\\n",
    "-result_path ../results/korean \\\n",
    "-bert_model /Users/imok/workspace/github/imOk/AI/model/001_bert_morp_pytorch \\\n",
    "-bert_config_path /Users/imok/workspace/github/imOk/AI/model/001_bert_morp_pytorch/bert_config.json -temp_dir ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xw_x2sIFnGOP"
   },
   "source": [
    "### (4) Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 20049,
     "status": "ok",
     "timestamp": 1649953715802,
     "user": {
      "displayName": "ImOk",
      "userId": "13644748134003701721"
     },
     "user_tz": -540
    },
    "id": "CyqR1dIY6Ttz",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "46171810-9730-4942-9625-3b645d7b22a0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-04-14 16:28:20,111 INFO] Loading checkpoint from ../models/bert_classifier/model_step_1000.pt\n",
      "Namespace(accum_count=1, batch_size=1000, bert_config_path='/content/drive/MyDrive/AI/model/001_bert_morp_pytorch/bert_config.json', bert_data_path='/content/drive/MyDrive/AI/KorBertSum/bert_data/eunok/korean', bert_model='/content/drive/MyDrive/AI/model/001_bert_morp_pytorch', beta1=0.9, beta2=0.999, block_trigram=True, dataset='', decay_method='noam', dropout=0.1, encoder='classifier', ff_size=512, gpu_ranks=[0], heads=4, hidden_size=128, inter_layers=2, log_file='../logs/bert_classifier', lr=0.002, max_grad_norm=0, mode='test', model_path='../models/bert_classifier', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=50, report_rouge=True, result_path='../results/korean', rnn_size=512, save_checkpoint_steps=1000, seed=666, temp_dir='.', test_all=False, test_from='../models/bert_classifier/model_step_1000.pt', train_from='', train_steps=1000, use_interval=True, visible_gpus='0', warmup_steps=8000, world_size=1)\n",
      "[2022-04-14 16:28:23,176 INFO] loading archive file /content/drive/MyDrive/AI/model/001_bert_morp_pytorch\n",
      "[2022-04-14 16:28:23,177 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-14 16:28:30,753 INFO] Loading test dataset from /content/drive/MyDrive/AI/KorBertSum/bert_data/eunok/korean.test.7318.bert.pt\n",
      "[2022-04-14 16:28:31,041 INFO] Loaded test dataset from /content/drive/MyDrive/AI/KorBertSum/bert_data/eunok/korean.test.7318.bert.pt, number of examples: 5\n",
      "gpu_rank 0\n",
      "[2022-04-14 16:28:31,049 INFO] * number of parameters: 109350145\n",
      "5\n",
      "5\n",
      "2022-04-14 16:28:31,541 [MainThread  ] [INFO ]  Writing summaries.\n",
      "[2022-04-14 16:28:31,541 INFO] Writing summaries.\n",
      "2022-04-14 16:28:31,546 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ./tmpfh72k6c6/system and model files to ./tmpfh72k6c6/model.\n",
      "[2022-04-14 16:28:31,546 INFO] Processing summaries. Saving system files to ./tmpfh72k6c6/system and model files to ./tmpfh72k6c6/model.\n",
      "2022-04-14 16:28:31,546 [MainThread  ] [INFO ]  Processing files in ./rouge-tmp-2022-04-14-16-28-31/candidate/.\n",
      "[2022-04-14 16:28:31,546 INFO] Processing files in ./rouge-tmp-2022-04-14-16-28-31/candidate/.\n",
      "2022-04-14 16:28:31,568 [MainThread  ] [INFO ]  Saved processed files to ./tmpfh72k6c6/system.\n",
      "[2022-04-14 16:28:31,568 INFO] Saved processed files to ./tmpfh72k6c6/system.\n",
      "2022-04-14 16:28:31,569 [MainThread  ] [INFO ]  Processing files in ./rouge-tmp-2022-04-14-16-28-31/reference/.\n",
      "[2022-04-14 16:28:31,569 INFO] Processing files in ./rouge-tmp-2022-04-14-16-28-31/reference/.\n",
      "2022-04-14 16:28:31,621 [MainThread  ] [INFO ]  Saved processed files to ./tmpfh72k6c6/model.\n",
      "[2022-04-14 16:28:31,621 INFO] Saved processed files to ./tmpfh72k6c6/model.\n",
      "2022-04-14 16:28:31,627 [MainThread  ] [INFO ]  Written ROUGE configuration to ./tmpm7x8vxws/rouge_conf.xml\n",
      "[2022-04-14 16:28:31,627 INFO] Written ROUGE configuration to ./tmpm7x8vxws/rouge_conf.xml\n",
      "2022-04-14 16:28:31,628 [MainThread  ] [INFO ]  Running ROUGE with command /content/drive/MyDrive/AI/pyrouge/pyrouge/rouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/MyDrive/AI/pyrouge/pyrouge/rouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./tmpm7x8vxws/rouge_conf.xml\n",
      "[2022-04-14 16:28:31,628 INFO] Running ROUGE with command /content/drive/MyDrive/AI/pyrouge/pyrouge/rouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/MyDrive/AI/pyrouge/pyrouge/rouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./tmpm7x8vxws/rouge_conf.xml\n",
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.92168 (95%-conf.int. 0.76000 - 1.00000)\n",
      "1 ROUGE-1 Average_P: 0.83337 (95%-conf.int. 0.71667 - 0.95000)\n",
      "1 ROUGE-1 Average_F: 0.86556 (95%-conf.int. 0.75810 - 0.97143)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.45235 (95%-conf.int. 0.05000 - 0.85000)\n",
      "1 ROUGE-2 Average_P: 0.32073 (95%-conf.int. 0.06667 - 0.57333)\n",
      "1 ROUGE-2 Average_F: 0.36856 (95%-conf.int. 0.05714 - 0.67714)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.92168 (95%-conf.int. 0.76000 - 1.00000)\n",
      "1 ROUGE-L Average_P: 0.83337 (95%-conf.int. 0.71667 - 0.95000)\n",
      "1 ROUGE-L Average_F: 0.86556 (95%-conf.int. 0.75810 - 0.97143)\n",
      "\n",
      "[2022-04-14 16:28:34,703 INFO] Rouges at step 1000 \n",
      ">> ROUGE-F(1/2/3/l): 86.56/36.86/86.56\n",
      "ROUGE-R(1/2/3/l): 92.17/45.23/92.17\n",
      "\n",
      "[2022-04-14 16:28:34,703 INFO] Validation xent: 3.38433 at step 1000\n"
     ]
    }
   ],
   "source": [
    "!python train.py -mode test -encoder classifier -dropout 0.1 \\\n",
    "-test_from ../models/bert_classifier/model_step_1000.pt \\\n",
    "-bert_data_path /Users/imok/workspace/github/imOk/AI/KorBertSum/bert_data/korean \\\n",
    "-model_path ../models/bert_classifier \\\n",
    "-lr 2e-3 -visible_gpus 0 -gpu_ranks 0 -world_size 1 -report_every 50 -save_checkpoint_steps 1000 \\\n",
    "-batch_size 1000 -decay_method noam -train_steps 1000 -accum_count 1 \\\n",
    "-log_file ../logs/bert_classifier -use_interval true -warmup_steps 8000 \\\n",
    "-result_path ../results/korean \\\n",
    "-bert_model /Users/imok/workspace/github/imOk/AI/model/001_bert_morp_pytorch \\\n",
    "-bert_config_path /Users/imok/workspace/github/imOk/AI/model/001_bert_morp_pytorch/bert_config.json -temp_dir ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_ozDH84-sIy"
   },
   "source": [
    "#### 라벨 데이터 & 예측 데이터 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1649987245859,
     "user": {
      "displayName": "김은옥정보통계학과",
      "userId": "15804471841108244937"
     },
     "user_tz": -540
    },
    "id": "I4XiKl1bBCzx"
   },
   "outputs": [],
   "source": [
    "with open('/Users/imok/workspace/github/imOk/AI/KorBertSum/results/korean_step1000.gold','r') as f:\n",
    "    gold = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1649987247839,
     "user": {
      "displayName": "김은옥정보통계학과",
      "userId": "15804471841108244937"
     },
     "user_tz": -540
    },
    "id": "RLeSh28iBFrd"
   },
   "outputs": [],
   "source": [
    "with open('/Users/imok/workspace/github/imOk/AI/KorBertSum/results/korean_step1000.candidate','r') as f:\n",
    "    candidate = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "executionInfo": {
     "elapsed": 1100,
     "status": "ok",
     "timestamp": 1649988629764,
     "user": {
      "displayName": "김은옥정보통계학과",
      "userId": "15804471841108244937"
     },
     "user_tz": -540
    },
    "id": "ug80ReulBHHt",
    "outputId": "86526ede-8254-4756-8342-abaccd4c6492"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'우리금융그룹 은 자회사 인 우리 은행 이 오 는 26 일 주식 시장 개장 전 시간 외 대량 매매 방식 으로 우리 금융 지분 4 %( 2889 만 707 주 ) 를 푸 본 생명 에 매각 한다고 25 일 밝혔 다 .'<q> '우리 은행 은 지난 10 일 자회사 였 던 우리 카드 를 우리 금융 지주 자회사 로 편입 시키 는 과정 에서 주당 1 만 2350 원 에 우리 금융 지주 지분 ( 5 . 8 %) 을 취득 했 다 . <q> '우리 금융 과 우리 은행 은 지난 4 월 부터 공동 태 스 크 포스 ( TF ) 를 만들 고 우리 은행 이 받 게 될 우리 금융 지주 주식 을 매각 하 는 방안 을 강구 해 왔 다 .\\n\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라벨 데이터\n",
    "gold[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1649988630853,
     "user": {
      "displayName": "김은옥정보통계학과",
      "userId": "15804471841108244937"
     },
     "user_tz": -540
    },
    "id": "fah9l5uYBJw2",
    "outputId": "72f0263a-0d80-41e4-e18d-c624c72d0a3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'우리금융그룹 은 자회사 인 우리 은행 이 오 는 26 일 주식 시장 개장 전 시간 외 대량 매매 방식 으로 우리 금융 지분 4 %( 2889 만 707 주 ) 를 푸 본 생명 에 매각 한다고 25 일 밝혔 다 .'<q>'우리 은행 은 지난 10 일 자회사 였 던 우리 카드 를 우리 금융 지주 자회사 로 편입 시키 는 과정 에서 주당 1 만 2350 원 에 우리 금융 지주 지분 ( 5 . 8 %) 을 취득 했 다 .<q>철저 한 사전 준비 와 적극 적 투자자 유치 활동 을 통해 글로벌 금융 시장 의 불안 에 도 불구 하 고 성공 적 지분 매각 이 라는 결실 을 맺 을 수 있 었 다고 우리 금융 측 은 설명 했 다 .'\\n\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 데이터\n",
    "candidate[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_mdCnedBMGF"
   },
   "source": [
    "## 4. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 452,
     "status": "ok",
     "timestamp": 1649987568485,
     "user": {
      "displayName": "김은옥정보통계학과",
      "userId": "15804471841108244937"
     },
     "user_tz": -540
    },
    "id": "8fYeEYUx6X63"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/Users/imok/workspace/github/imOk/AI/KorBertSum/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1649987568485,
     "user": {
      "displayName": "김은옥정보통계학과",
      "userId": "15804471841108244937"
     },
     "user_tz": -540
    },
    "id": "XCnbI-79uFS-"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from models import data_loader, model_builder\n",
    "from models.model_builder import Summarizer\n",
    "from others.logging import logger, init_logger\n",
    "from models.data_loader import load_dataset\n",
    "from transformers import BertConfig, BertTokenizer\n",
    "from tensorboardX import SummaryWriter\n",
    "from models.reporter import ReportMgr\n",
    "from models.stats import Statistics\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1649987571990,
     "user": {
      "displayName": "김은옥정보통계학과",
      "userId": "15804471841108244937"
     },
     "user_tz": -540
    },
    "id": "kMkoM4s-uOMG",
    "outputId": "58ffbdb2-68aa-4b76-cb95-9caaeaaca2fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/imok/workspace/github/imOk/AI/KorBertSum\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 382,
     "status": "ok",
     "timestamp": 1649988489578,
     "user": {
      "displayName": "김은옥정보통계학과",
      "userId": "15804471841108244937"
     },
     "user_tz": -540
    },
    "id": "8xFVdtZBuQHK",
    "outputId": "9798e976-f9e1-46b2-b706-d96d3bb465e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/imok/workspace/github/imOk/AI/KorBertSum\n"
     ]
    }
   ],
   "source": [
    "cd /Users/imok/workspace/github/imOk/AI/KorBertSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "executionInfo": {
     "elapsed": 2091,
     "status": "ok",
     "timestamp": 1649987776149,
     "user": {
      "displayName": "김은옥정보통계학과",
      "userId": "15804471841108244937"
     },
     "user_tz": -540
    },
    "id": "aqtidESK65f0"
   },
   "outputs": [],
   "source": [
    "def _tally_parameters(model):\n",
    "    n_params = sum([p.nelement() for p in model.parameters()])\n",
    "    return n_params\n",
    "\n",
    "def build_trainer(args, device_id, model,\n",
    "                  optim):\n",
    "    \"\"\"\n",
    "    Simplify `Trainer` creation based on user `opt`s*\n",
    "    Args:\n",
    "        opt (:obj:`Namespace`): user options (usually from argument parsing)\n",
    "        model (:obj:`onmt.models.NMTModel`): the model to train\n",
    "        fields (dict): dict of fields\n",
    "        optim (:obj:`onmt.utils.Optimizer`): optimizer used during training\n",
    "        data_type (str): string describing the type of data\n",
    "            e.g. \"text\", \"img\", \"audio\"\n",
    "        model_saver(:obj:`onmt.models.ModelSaverBase`): the utility object\n",
    "            used to save the model\n",
    "    \"\"\"\n",
    "    device = \"cpu\" if args.visible_gpus == '-1' else \"cuda\"\n",
    "\n",
    "\n",
    "    grad_accum_count = args.accum_count\n",
    "    n_gpu = args.world_size\n",
    "\n",
    "    if device_id >= 0:\n",
    "        gpu_rank = int(args.gpu_ranks[device_id])\n",
    "    else:\n",
    "        gpu_rank = 0\n",
    "        n_gpu = 0\n",
    "\n",
    "    print('gpu_rank %d' % gpu_rank)\n",
    "\n",
    "    tensorboard_log_dir = args.model_path\n",
    "\n",
    "    writer = SummaryWriter(tensorboard_log_dir, comment=\"Unmt\")\n",
    "\n",
    "    report_manager = ReportMgr(args.report_every, start_time=-1, tensorboard_writer=writer)\n",
    "\n",
    "    trainer = Trainer(args, model, optim, grad_accum_count, n_gpu, gpu_rank, report_manager)\n",
    "\n",
    "    # print(tr)\n",
    "    if (model):\n",
    "        n_params = _tally_parameters(model)\n",
    "        logger.info('* number of parameters: %d' % n_params)\n",
    "\n",
    "    return trainer\n",
    "\n",
    "\n",
    "class Trainer(object):\n",
    "    \"\"\"\n",
    "    Class that controls the training process.\n",
    "\n",
    "    Args:\n",
    "            model(:py:class:`onmt.models.model.NMTModel`): translation model\n",
    "                to train\n",
    "            train_loss(:obj:`onmt.utils.loss.LossComputeBase`):\n",
    "               training loss computation\n",
    "            valid_loss(:obj:`onmt.utils.loss.LossComputeBase`):\n",
    "               training loss computation\n",
    "            optim(:obj:`onmt.utils.optimizers.Optimizer`):\n",
    "               the optimizer responsible for update\n",
    "            trunc_size(int): length of truncated back propagation through time\n",
    "            shard_size(int): compute loss in shards of this size for efficiency\n",
    "            data_type(string): type of the source input: [text|img|audio]\n",
    "            norm_method(string): normalization methods: [sents|tokens]\n",
    "            grad_accum_count(int): accumulate gradients this many times.\n",
    "            report_manager(:obj:`onmt.utils.ReportMgrBase`):\n",
    "                the object that creates reports, or None\n",
    "            model_saver(:obj:`onmt.models.ModelSaverBase`): the saver is\n",
    "                used to save a checkpoint.\n",
    "                Thus nothing will be saved if this parameter is None\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,  args, model,  optim,\n",
    "                  grad_accum_count=1, n_gpu=1, gpu_rank=1,\n",
    "                  report_manager=None):\n",
    "        # Basic attributes.\n",
    "        self.args = args\n",
    "        self.save_checkpoint_steps = args.save_checkpoint_steps\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.grad_accum_count = grad_accum_count\n",
    "        self.n_gpu = n_gpu\n",
    "        self.gpu_rank = gpu_rank\n",
    "        self.report_manager = report_manager\n",
    "\n",
    "        self.loss = torch.nn.BCELoss(reduction='none')\n",
    "        assert grad_accum_count > 0\n",
    "        # Set model in training mode.\n",
    "        if (model):\n",
    "            self.model.train()\n",
    "\n",
    "    def summ(self, test_iter, step, cal_lead=False, cal_oracle=False):\n",
    "        \"\"\" Validate model.\n",
    "            valid_iter: validate data iterator\n",
    "        Returns:\n",
    "            :obj:`nmt.Statistics`: validation loss statistics\n",
    "        \"\"\"\n",
    "      # Set model in validating mode.\n",
    "        def _get_ngrams(n, text):\n",
    "            ngram_set = set()\n",
    "            text_length = len(text)\n",
    "            max_index_ngram_start = text_length - n\n",
    "            for i in range(max_index_ngram_start + 1):\n",
    "                ngram_set.add(tuple(text[i:i + n]))\n",
    "            return ngram_set\n",
    "\n",
    "        def _block_tri(c, p):\n",
    "            tri_c = _get_ngrams(3, c.split())\n",
    "            for s in p:\n",
    "                tri_s = _get_ngrams(3, s.split())\n",
    "                if len(tri_c.intersection(tri_s))>0:\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "        if (not cal_lead and not cal_oracle):\n",
    "            self.model.eval()\n",
    "        stats = Statistics()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in test_iter:\n",
    "                src = batch.src\n",
    "                labels = batch.labels\n",
    "                segs = batch.segs\n",
    "                clss = batch.clss\n",
    "                mask = batch.mask\n",
    "                mask_cls = batch.mask_cls\n",
    "\n",
    "                if (cal_lead):\n",
    "                    selected_ids = [list(range(batch.clss.size(1)))] * batch.batch_size\n",
    "                elif (cal_oracle):\n",
    "                    selected_ids = [[j for j in range(batch.clss.size(1)) if labels[i][j] == 1] for i in\n",
    "                                    range(batch.batch_size)]\n",
    "                else:\n",
    "                    sent_scores, mask = self.model(src, segs, clss, mask, mask_cls)\n",
    "                    sent_scores = sent_scores + mask.float()\n",
    "                    sent_scores = sent_scores.cpu().data.numpy()\n",
    "                    selected_ids = np.argsort(-sent_scores, 1)\n",
    "        return selected_ids\n",
    "\n",
    "\n",
    "\n",
    "    def _gradient_accumulation(self, true_batchs, normalization, total_stats,\n",
    "                               report_stats):\n",
    "        if self.grad_accum_count > 1:\n",
    "            self.model.zero_grad()\n",
    "\n",
    "        for batch in true_batchs:\n",
    "            if self.grad_accum_count == 1:\n",
    "                self.model.zero_grad()\n",
    "\n",
    "            src = batch.src\n",
    "            labels = batch.labels\n",
    "            segs = batch.segs\n",
    "            clss = batch.clss\n",
    "            mask = batch.mask\n",
    "            mask_cls = batch.mask_cls\n",
    "\n",
    "            sent_scores, mask = self.model(src, segs, clss, mask, mask_cls)\n",
    "\n",
    "            loss = self.loss(sent_scores, labels.float())\n",
    "            loss = (loss*mask.float()).sum()\n",
    "            (loss/loss.numel()).backward()\n",
    "            # loss.div(float(normalization)).backward()\n",
    "\n",
    "            batch_stats = Statistics(float(loss.cpu().data.numpy()), normalization)\n",
    "\n",
    "\n",
    "            total_stats.update(batch_stats)\n",
    "            report_stats.update(batch_stats)\n",
    "\n",
    "            # 4. Update the parameters and statistics.\n",
    "            if self.grad_accum_count == 1:\n",
    "                # Multi GPU gradient gather\n",
    "                if self.n_gpu > 1:\n",
    "                    grads = [p.grad.data for p in self.model.parameters()\n",
    "                             if p.requires_grad\n",
    "                             and p.grad is not None]\n",
    "                    distributed.all_reduce_and_rescale_tensors(\n",
    "                        grads, float(1))\n",
    "                self.optim.step()\n",
    "\n",
    "        # in case of multi step gradient accumulation,\n",
    "        # update only after accum batches\n",
    "        if self.grad_accum_count > 1:\n",
    "            if self.n_gpu > 1:\n",
    "                grads = [p.grad.data for p in self.model.parameters()\n",
    "                         if p.requires_grad\n",
    "                         and p.grad is not None]\n",
    "                distributed.all_reduce_and_rescale_tensors(\n",
    "                    grads, float(1))\n",
    "            self.optim.step()\n",
    "\n",
    "    def _save(self, step):\n",
    "        real_model = self.model\n",
    "        # real_generator = (self.generator.module\n",
    "        #                   if isinstance(self.generator, torch.nn.DataParallel)\n",
    "        #                   else self.generator)\n",
    "\n",
    "        model_state_dict = real_model.state_dict()\n",
    "        # generator_state_dict = real_generator.state_dict()\n",
    "        checkpoint = {\n",
    "            'model': model_state_dict,\n",
    "            # 'generator': generator_state_dict,\n",
    "            'opt': self.args,\n",
    "            'optim': self.optim,\n",
    "        }\n",
    "        checkpoint_path = os.path.join(self.args.model_path, 'model_step_%d.pt' % step)\n",
    "        logger.info(\"Saving checkpoint %s\" % checkpoint_path)\n",
    "        # checkpoint_path = '%s_step_%d.pt' % (FLAGS.model_path, step)\n",
    "        if (not os.path.exists(checkpoint_path)):\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "            return checkpoint, checkpoint_path\n",
    "\n",
    "    def _start_report_manager(self, start_time=None):\n",
    "        \"\"\"\n",
    "        Simple function to start report manager (if any)\n",
    "        \"\"\"\n",
    "        if self.report_manager is not None:\n",
    "            if start_time is None:\n",
    "                self.report_manager.start()\n",
    "            else:\n",
    "                self.report_manager.start_time = start_time\n",
    "\n",
    "    def _maybe_gather_stats(self, stat):\n",
    "        \"\"\"\n",
    "        Gather statistics in multi-processes cases\n",
    "\n",
    "        Args:\n",
    "            stat(:obj:onmt.utils.Statistics): a Statistics object to gather\n",
    "                or None (it returns None in this case)\n",
    "\n",
    "        Returns:\n",
    "            stat: the updated (or unchanged) stat object\n",
    "        \"\"\"\n",
    "        if stat is not None and self.n_gpu > 1:\n",
    "            return Statistics.all_gather_stats(stat)\n",
    "        return stat\n",
    "\n",
    "    def _maybe_report_training(self, step, num_steps, learning_rate,\n",
    "                               report_stats):\n",
    "        \"\"\"\n",
    "        Simple function to report training stats (if report_manager is set)\n",
    "        see `onmt.utils.ReportManagerBase.report_training` for doc\n",
    "        \"\"\"\n",
    "        if self.report_manager is not None:\n",
    "            return self.report_manager.report_training(\n",
    "                step, num_steps, learning_rate, report_stats,\n",
    "                multigpu=self.n_gpu > 1)\n",
    "\n",
    "    def _report_step(self, learning_rate, step, train_stats=None,\n",
    "                     valid_stats=None):\n",
    "        \"\"\"\n",
    "        Simple function to report stats (if report_manager is set)\n",
    "        see `onmt.utils.ReportManagerBase.report_step` for doc\n",
    "        \"\"\"\n",
    "        if self.report_manager is not None:\n",
    "            return self.report_manager.report_step(\n",
    "                learning_rate, step, train_stats=train_stats,\n",
    "                valid_stats=valid_stats)\n",
    "\n",
    "    def _maybe_save(self, step):\n",
    "        \"\"\"\n",
    "        Save the model if a model saver is set\n",
    "        \"\"\"\n",
    "        if self.model_saver is not None:\n",
    "            self.model_saver.maybe_save(step)\n",
    "\n",
    "class BertData():\n",
    "    def __init__(self):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.sep_vid = self.tokenizer.vocab['[SEP]']\n",
    "        self.cls_vid = self.tokenizer.vocab['[CLS]']\n",
    "        self.pad_vid = self.tokenizer.vocab['[PAD]']\n",
    "\n",
    "    def preprocess(self, src):\n",
    "\n",
    "        if (len(src) == 0):\n",
    "            return None\n",
    "\n",
    "        original_src_txt = [' '.join(s) for s in src]\n",
    "        idxs = [i for i, s in enumerate(src) if (len(s) > 1)]\n",
    "\n",
    "        src = [src[i][:2000] for i in idxs]\n",
    "        src = src[:1000]\n",
    "\n",
    "        if (len(src) < 3):\n",
    "            return None\n",
    "\n",
    "        src_txt = [' '.join(sent) for sent in src]\n",
    "        text = ' [SEP] [CLS] '.join(src_txt)\n",
    "        src_subtokens = self.tokenizer.tokenize(text)\n",
    "        src_subtokens = src_subtokens[:510]\n",
    "        src_subtokens = ['[CLS]'] + src_subtokens + ['[SEP]']\n",
    "\n",
    "        src_subtoken_idxs = self.tokenizer.convert_tokens_to_ids(src_subtokens)\n",
    "        _segs = [-1] + [i for i, t in enumerate(src_subtoken_idxs) if t == self.sep_vid]\n",
    "        segs = [_segs[i] - _segs[i - 1] for i in range(1, len(_segs))]\n",
    "        segments_ids = []\n",
    "        for i, s in enumerate(segs):\n",
    "            if (i % 2 == 0):\n",
    "                segments_ids += s * [0]\n",
    "            else:\n",
    "                segments_ids += s * [1]\n",
    "        cls_ids = [i for i, t in enumerate(src_subtoken_idxs) if t == self.cls_vid]\n",
    "        labels = None\n",
    "        src_txt = [original_src_txt[i] for i in idxs]\n",
    "        tgt_txt = None\n",
    "        return src_subtoken_idxs, labels, segments_ids, cls_ids, src_txt, tgt_txt\n",
    "\n",
    "def _lazy_dataset_loader(pt_file):\n",
    "    yield  pt_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Mmlc2pvvIms"
   },
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1649987776551,
     "user": {
      "displayName": "김은옥정보통계학과",
      "userId": "15804471841108244937"
     },
     "user_tz": -540
    },
    "id": "pP-DbngyuLRb"
   },
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"encoder\":'classifier',\n",
    "    \"mode\":'test',\n",
    "    \"bert_data_path\":'/Users/imok/workspace/github/imOk/AI/KorBertSum/bert_data/korean',\n",
    "    \"model_path\":'../models/bert_classifier',\n",
    "    \"result_path\":'./results',\n",
    "    \"temp_dir\":'./temp',\n",
    "    \"batch_size\":1000,\n",
    "    \"use_interval\":True,\n",
    "    \"hidden_size\":128,\n",
    "    \"ff_size\":512,\n",
    "    \"heads\":4,\n",
    "    \"inter_layers\":2,\n",
    "    \"rnn_size\":512,\n",
    "    \"param_init\":0,\n",
    "    \"param_init_glorot\":True,\n",
    "    \"dropout\":0.1,\n",
    "    \"optim\":'adam',\n",
    "    \"lr\":2e-3,\n",
    "    \"report_every\":1,\n",
    "    \"save_checkpoint_steps\":5,\n",
    "    \"block_trigram\":True,\n",
    "    \"recall_eval\":False,\n",
    "    \"bert_model\":'/Users/imok/workspace/github/imOk/AI/model/001_bert_morp_pytorch',\n",
    "    \"bert_config_path\": '/Users/imok/workspace/github/imOk/AI/model/001_bert_morp_pytorch/bert_config.json',\n",
    "    \"accum_count\":1,\n",
    "    \"world_size\":1,\n",
    "    \"visible_gpus\":'-1',\n",
    "    \"gpu_ranks\":'0',\n",
    "    \"log_file\":'/Users/imok/workspace/github/imOk/AI/KorBertSum/logs/log.log',\n",
    "    \"test_from\":'/Users/imok/workspace/github/imOk/AI/KorBertSum/models/bert_classifier/model_step_1000.pt'\n",
    "})\n",
    "model_flags = ['hidden_size', 'ff_size', 'heads', 'inter_layers','encoder','ff_actv', 'use_interval','rnn_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_6selHKvOu1"
   },
   "source": [
    "### Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1649987776863,
     "user": {
      "displayName": "김은옥정보통계학과",
      "userId": "15804471841108244937"
     },
     "user_tz": -540
    },
    "id": "KhWD_K526Oc5"
   },
   "outputs": [],
   "source": [
    "def test(args, input_list, device_id, pt, step):\n",
    "    init_logger(args.log_file)\n",
    "    device = \"cpu\" if args.visible_gpus == '-1' else \"cuda\"\n",
    "    device_id = 0 if device == \"cuda\" else -1\n",
    "\n",
    "    cp = args.test_from\n",
    "    try:\n",
    "        step = int(cp.split('.')[-2].split('_')[-1])\n",
    "    except:\n",
    "        step = 0\n",
    "\n",
    "    device = \"cpu\" if args.visible_gpus == '-1' else \"cuda\"\n",
    "    if (pt != ''):\n",
    "        test_from = pt\n",
    "    else:\n",
    "        test_from = args.test_from\n",
    "    logger.info('Loading checkpoint from %s' % test_from)\n",
    "    checkpoint = torch.load(test_from, map_location=lambda storage, loc: storage)\n",
    "    opt = vars(checkpoint['opt'])\n",
    "    for k in opt.keys():\n",
    "        if (k in model_flags):\n",
    "            setattr(args, k, opt[k])\n",
    "\n",
    "    config = BertConfig.from_pretrained('bert-base-multilingual-cased')\n",
    "    model = Summarizer(args, device, load_pretrained_bert=False, bert_config = config)\n",
    "    model.load_cp(checkpoint)\n",
    "    model.eval()\n",
    "\n",
    "    test_iter = data_loader.Dataloader(args, _lazy_dataset_loader(input_list),\n",
    "                                args.batch_size, device,\n",
    "                                shuffle=False, is_test=True)\n",
    "    trainer = build_trainer(args, device_id, model, None)\n",
    "    result = trainer.summ(test_iter,step)\n",
    "    return result, input_list\n",
    "\n",
    "args.gpu_ranks = [int(i) for i in args.gpu_ranks.split(',')]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.visible_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1649987779409,
     "user": {
      "displayName": "김은옥정보통계학과",
      "userId": "15804471841108244937"
     },
     "user_tz": -540
    },
    "id": "CnewmBJOtsvG"
   },
   "outputs": [],
   "source": [
    "def txt2input(text):\n",
    "    data = list(filter(None, text.split('\\n')))\n",
    "    bertdata = BertData()\n",
    "    txt_data = bertdata.preprocess(data)\n",
    "    data_dict = {\"src\":txt_data[0],\n",
    "               \"labels\":[0,1,2],\n",
    "               \"segs\":txt_data[2],\n",
    "               \"clss\":txt_data[3],\n",
    "               \"src_txt\":txt_data[4],\n",
    "               \"tgt_txt\":None}\n",
    "    input_data = []\n",
    "    input_data.append(data_dict)\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1649988727101,
     "user": {
      "displayName": "김은옥정보통계학과",
      "userId": "15804471841108244937"
     },
     "user_tz": -540
    },
    "id": "UD2Q20MH_YFC"
   },
   "outputs": [],
   "source": [
    "text = '''\n",
    "여덟 살짜리 소녀가 러시아의 침공으로 피해를 입은 우크라이나 어린이들을 위해 두 팔을 걷어붙이고 나섰다.\n",
    "6일 영국 bbc에 따르면 링컨셔주에 는 아바 로즈 클라크는 우크라이나 친구를 돕기 위해 4시간 챌린지를 시작했다.\n",
    "이 도전은 요크셔주와 링컨셔주를 잇는 전체 길이 20마일 규모의 험버 대교를 자전거로 건너는 것.\n",
    "도전 첫날이었던 지난 5일 아바 로즈는 험버 대교의 6마일을 횡단하는 데 성공했다.\n",
    "그는 우크라이나 어린이들이 평소 가지고 놀던 장난감과 물건을 버리고 피란하는 모습을 보며 도움을 줄 방법을 고민하던 중 챌린지를 생각해냈다고 말했다.\n",
    "유니세프를 통해 1000파운드를 목표로 시작한 아바 로즈의 모금 챌린지 누적 금액은 7일 기준 1065파운드를 넘겼다.\n",
    "험버 대교를 건너는 아바 로즈의 모습을 상상해서 그려주세요.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7983,
     "status": "ok",
     "timestamp": 1649988738947,
     "user": {
      "displayName": "김은옥정보통계학과",
      "userId": "15804471841108244937"
     },
     "user_tz": -540
    },
    "id": "pbOk0GTztx9W",
    "outputId": "583a5d83-b590-4b21-a23d-b88bf52559ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-15 13:44:25,365 INFO] Loading checkpoint from /Users/imok/workspace/github/imOk/AI/KorBertSum/models/bert_classifier/model_step_1000.pt\n",
      "[2022-04-15 13:44:27,074 INFO] loading archive file /Users/imok/workspace/github/imOk/AI/model/001_bert_morp_pytorch\n",
      "[2022-04-15 13:44:27,077 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-15 13:44:29,761 INFO] * number of parameters: 109350145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6, 3, 5, 0, 1, 4, 2]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = txt2input(text)\n",
    "sum_list = test(args, input_data, -1, '', None)\n",
    "sum_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ZIFOZYzvacA"
   },
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1649988739226,
     "user": {
      "displayName": "김은옥정보통계학과",
      "userId": "15804471841108244937"
     },
     "user_tz": -540
    },
    "id": "CzjdXZsut1xK",
    "outputId": "3edd8251-127c-43f5-b28b-565276a2e056"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['험버 대교를 건너는 아바 로즈의 모습을 상상해서 그려주세요.',\n",
       " '도전 첫날이었던 지난 5일 아바 로즈는 험버 대교의 6마일을 횡단하는 데 성공했다.',\n",
       " '유니세프를 통해 1000파운드를 목표로 시작한 아바 로즈의 모금 챌린지 누적 금액은 7일 기준 1065파운드를 넘겼다.']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(filter(None, text.split('\\n')))[i] for i in sum_list[0][0][:3]]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "koBertTest.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "imok",
   "language": "python",
   "name": "imok"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
