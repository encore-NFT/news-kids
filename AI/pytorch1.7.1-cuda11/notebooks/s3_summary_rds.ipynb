{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a34eb30-d30f-42c9-a406-7730881be488",
   "metadata": {},
   "source": [
    "# 📰 어린이 뉴스 Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f4ca62-a3a4-44f8-a6de-d124fd5ee544",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c1daee-9769-4a29-b688-490b80e73931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import io\n",
    "import boto3\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f1123-b075-475c-b60d-176c217bca00",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Amazon S3 to pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "820b31c2-132b-4e64-8405-2498aaa5e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "_key = pd.read_csv('/notebooks/rootkey.csv',sep='=',header=None)\n",
    "prefix = 'kid_news/'\n",
    "bucket_name = 'nft-newsdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18783c3a-ec92-44b9-87e5-13f570326798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# s3 connection check\n",
    "def s3_connection():\n",
    "    try:\n",
    "        s3 = boto3.client(\n",
    "            service_name=\"s3\",\n",
    "            region_name=\"ap-northeast-2\",\n",
    "            aws_access_key_id=_key[1][0],\n",
    "            aws_secret_access_key=_key[1][1],\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    else:\n",
    "        print(\"s3 bucket connected!\")\n",
    "        return s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8d1ae2d-4786-4f8c-8252-1dbcc19795db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3 bucket connected!\n"
     ]
    }
   ],
   "source": [
    "s3 = s3_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f8ae9da-f2bc-40ef-b9f0-70dc584fd876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 전체 파일목록\n",
    "def s3_get_all_keys(**args):\n",
    "    keys = []\n",
    "    page_iterator = s3.get_paginator(\"list_objects_v2\")\n",
    "\n",
    "    for page in page_iterator.paginate(**args):\n",
    "        try:\n",
    "            contents = page['Contents']\n",
    "        except KeyError:\n",
    "            break\n",
    "            \n",
    "        for item in contents:\n",
    "            keys.append(item['Key'])\n",
    "            \n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fb1e861-781d-4032-97cd-16098a344fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_from_s3(filename):\n",
    "    obj = s3.get_object(Bucket=bucket_name,Key=filename)\n",
    "    result_byte= io.BytesIO(obj[\"Body\"].read())\n",
    "    return result_byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f6eac9d-c4cc-4505-9a4d-87353cf175b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_file_list = s3_get_all_keys(Bucket=bucket_name, Prefix=prefix)\n",
    "json_file = []\n",
    "for f in json_file_list : \n",
    "    json_file.append(read_json_from_s3(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee0a3f9e-3c85-4114-b1c4-7c9e28793ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for file in json_file:\n",
    "    data = pd.read_json(file)\n",
    "    df = pd.concat([df, data])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39993f8-5313-475b-a062-51e597c9544b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1057f4aa-d9bb-4d80-bab9-d0154c647c51",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42795b84-bec3-424c-b13b-246c0b7cfc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['news_len'] = df['news_article'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9e0e45a-d8a2-4068-b758-7403ba532484",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_url</th>\n",
       "      <th>news_title</th>\n",
       "      <th>news_subtitle</th>\n",
       "      <th>news_writer</th>\n",
       "      <th>news_date</th>\n",
       "      <th>news_article</th>\n",
       "      <th>news_img</th>\n",
       "      <th>news_source</th>\n",
       "      <th>news_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://kid.chosun.com/site/data/html_dir/2022/...</td>\n",
       "      <td>[아는 것이 힘이다!] 아메리카 인디언의 벌새 전설, 기생충과 박테리아</td>\n",
       "      <td></td>\n",
       "      <td>현기성 기자</td>\n",
       "      <td>2022-04-19 00:01</td>\n",
       "      <td>아메리카 인디언의 벌새 전설 아주 먼 옛날, 인간이 생기기도 전에 거대한 불길이 느...</td>\n",
       "      <td>http://kid.chosun.com/site/data/img_dir/2022/0...</td>\n",
       "      <td>어린이조선일보</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://kid.chosun.com/site/data/html_dir/2022/...</td>\n",
       "      <td>거리 두기 끝… 일상 되찾는 학교, 확진돼도 기말고사 치를 수 있다</td>\n",
       "      <td>‘5월 이후 정상 등교’ 여부 검토 중</td>\n",
       "      <td>진현경 기자</td>\n",
       "      <td>2022-04-19 00:01</td>\n",
       "      <td>어제(18일)부터 마스크 착용을 제외한 '사회적 거리 두기'가 전면 해제됐다. 사적...</td>\n",
       "      <td>http://kid.chosun.com/site/data/img_dir/2022/0...</td>\n",
       "      <td>어린이조선일보</td>\n",
       "      <td>838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            news_url  \\\n",
       "0  http://kid.chosun.com/site/data/html_dir/2022/...   \n",
       "1  http://kid.chosun.com/site/data/html_dir/2022/...   \n",
       "\n",
       "                                news_title          news_subtitle news_writer  \\\n",
       "0  [아는 것이 힘이다!] 아메리카 인디언의 벌새 전설, 기생충과 박테리아                             현기성 기자   \n",
       "1    거리 두기 끝… 일상 되찾는 학교, 확진돼도 기말고사 치를 수 있다  ‘5월 이후 정상 등교’ 여부 검토 중      진현경 기자   \n",
       "\n",
       "          news_date                                       news_article  \\\n",
       "0  2022-04-19 00:01  아메리카 인디언의 벌새 전설 아주 먼 옛날, 인간이 생기기도 전에 거대한 불길이 느...   \n",
       "1  2022-04-19 00:01  어제(18일)부터 마스크 착용을 제외한 '사회적 거리 두기'가 전면 해제됐다. 사적...   \n",
       "\n",
       "                                            news_img news_source  news_len  \n",
       "0  http://kid.chosun.com/site/data/img_dir/2022/0...     어린이조선일보       830  \n",
       "1  http://kid.chosun.com/site/data/img_dir/2022/0...     어린이조선일보       838  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기사의 길이가 300개 아래인 경우 버림\n",
    "# 문장 요약을 위해 세 문장보다 많은 기사를 확보하기 위함\n",
    "df = df[df['news_len'] > 300].reset_index(drop=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b44c175-e760-47e7-9933-508eec96824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text): \n",
    "    text = re.sub(r'(\\[)(.*?)(\\])','',str(text)) # remove [title]\n",
    "    text = re.sub(r'(\\()(.*?)(\\))', '', text)  # 소괄호 (세부 설명\n",
    "    text = re.sub(r'[?!]', '.', text)          # ?! => 마침표 처리\n",
    "    text = re.sub(r'[\\,\\·\\:\\-\\_]', ' ', text)  # 문장부호 구분자 => 공백 처리\n",
    "    text = text.lower() #lower case \n",
    "    text = re.sub(r'\\s+', ' ', text) #remove extra space\n",
    "    # text = re.sub(r'<[^>]+>','',text) #remove Html tags \n",
    "    text = re.sub(r'<[^가-힣]+>','',text)# 홑화살괄호 => 한글만 빼고 제거\n",
    "    text = re.sub(r'^\\s+', '', text) #remove space from start\n",
    "    text = re.sub(r'\\s+$', '', text) #remove space from the end\n",
    "    text = re.sub('[^가-힣\\w. ]', '', text)    # 한글, 문자, 숫자, 마침표, 공백 제외 제거\n",
    "    text = re.sub(r'[一-龥]', '', text) #remove Chinese character\n",
    "    text = re.sub('\\s{2,}', ' ', text)        # 2번 이상의 space 제거\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a98aff4b-6cbf-437a-9952-2fdb94e31576",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"news_title\"] = df[\"news_title\"].apply(clean_text)\n",
    "df[\"news_article\"] = df[\"news_article\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28acfd16-a739-4b54-9852-f888607d4b2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "news_df = df[['news_source', 'news_date','news_url','news_title','news_img','news_article']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4c2d87-82a3-41a7-8867-331bccca0d08",
   "metadata": {},
   "source": [
    "```\n",
    "+--------------+--------------+------+-----+---------+----------------+\n",
    "| Field        | Type         | Null | Key | Default | Extra          |\n",
    "+--------------+--------------+------+-----+---------+----------------+\n",
    "| id           | bigint       | NO   | PRI | NULL    | auto_increment |\n",
    "| news_source  | varchar(20)  | NO   |     | NULL    |                |\n",
    "| news_date    | datetime(6)  | NO   |     | NULL    |                |\n",
    "| news_url     | varchar(500) | NO   |     | NULL    |                |\n",
    "| news_title   | varchar(200) | NO   |     | NULL    |                |\n",
    "| news_image   | varchar(500) | YES  |     | NULL    |                |\n",
    "| news_article | longtext     | YES  |     | NULL    |                |\n",
    "+--------------+--------------+------+-----+---------+----------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3801cf09-e3fd-47b2-b279-8dbae8f513d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_source</th>\n",
       "      <th>news_date</th>\n",
       "      <th>news_url</th>\n",
       "      <th>news_title</th>\n",
       "      <th>news_img</th>\n",
       "      <th>news_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>어린이조선일보</td>\n",
       "      <td>2022-04-19 00:01</td>\n",
       "      <td>http://kid.chosun.com/site/data/html_dir/2022/...</td>\n",
       "      <td>아메리카 인디언의 벌새 전설 기생충과 박테리아</td>\n",
       "      <td>http://kid.chosun.com/site/data/img_dir/2022/0...</td>\n",
       "      <td>아메리카 인디언의 벌새 전설 아주 먼 옛날 인간이 생기기도 전에 거대한 불길이 느닷...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  news_source         news_date  \\\n",
       "0     어린이조선일보  2022-04-19 00:01   \n",
       "\n",
       "                                            news_url  \\\n",
       "0  http://kid.chosun.com/site/data/html_dir/2022/...   \n",
       "\n",
       "                  news_title  \\\n",
       "0  아메리카 인디언의 벌새 전설 기생충과 박테리아   \n",
       "\n",
       "                                            news_img  \\\n",
       "0  http://kid.chosun.com/site/data/img_dir/2022/0...   \n",
       "\n",
       "                                        news_article  \n",
       "0  아메리카 인디언의 벌새 전설 아주 먼 옛날 인간이 생기기도 전에 거대한 불길이 느닷...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8be59a-660a-49a8-a974-11b26d03b43f",
   "metadata": {
    "id": "E_mdCnedBMGF"
   },
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad3d3c19-cc2b-4eb0-863c-517786591d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c2e3a8c-c789-4e4e-9a1c-e43250264b8c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-23 20:31:41,401 INFO] Loading checkpoint from /notebooks/KorBertSum/models/bert_classifier/backup/model_step_10000.pt\n",
      "[2022-04-23 20:31:47,017 INFO] loading archive file /notebooks/model/001_bert_morp_pytorch\n",
      "[2022-04-23 20:31:47,022 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-23 20:31:50,063 INFO] * number of parameters: 109350145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-23 20:31:54,967 INFO] Loading checkpoint from /notebooks/KorBertSum/models/bert_classifier/backup/model_step_10000.pt\n",
      "[2022-04-23 20:32:00,953 INFO] loading archive file /notebooks/model/001_bert_morp_pytorch\n",
      "[2022-04-23 20:32:00,958 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-23 20:32:04,063 INFO] * number of parameters: 109350145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-23 20:32:08,982 INFO] Loading checkpoint from /notebooks/KorBertSum/models/bert_classifier/backup/model_step_10000.pt\n",
      "[2022-04-23 20:32:15,079 INFO] loading archive file /notebooks/model/001_bert_morp_pytorch\n",
      "[2022-04-23 20:32:15,084 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-23 20:32:18,236 INFO] * number of parameters: 109350145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-23 20:32:22,896 INFO] Loading checkpoint from /notebooks/KorBertSum/models/bert_classifier/backup/model_step_10000.pt\n",
      "[2022-04-23 20:32:29,021 INFO] loading archive file /notebooks/model/001_bert_morp_pytorch\n",
      "[2022-04-23 20:32:29,026 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-23 20:32:32,163 INFO] * number of parameters: 109350145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-23 20:32:37,137 INFO] Loading checkpoint from /notebooks/KorBertSum/models/bert_classifier/backup/model_step_10000.pt\n",
      "[2022-04-23 20:32:42,631 INFO] loading archive file /notebooks/model/001_bert_morp_pytorch\n",
      "[2022-04-23 20:32:42,635 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-23 20:32:45,587 INFO] * number of parameters: 109350145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-23 20:32:50,161 INFO] Loading checkpoint from /notebooks/KorBertSum/models/bert_classifier/backup/model_step_10000.pt\n",
      "[2022-04-23 20:32:55,732 INFO] loading archive file /notebooks/model/001_bert_morp_pytorch\n",
      "[2022-04-23 20:32:55,736 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-23 20:32:58,657 INFO] * number of parameters: 109350145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-23 20:33:03,419 INFO] Loading checkpoint from /notebooks/KorBertSum/models/bert_classifier/backup/model_step_10000.pt\n",
      "[2022-04-23 20:33:08,881 INFO] loading archive file /notebooks/model/001_bert_morp_pytorch\n",
      "[2022-04-23 20:33:08,887 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-23 20:33:11,809 INFO] * number of parameters: 109350145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-23 20:33:16,750 INFO] Loading checkpoint from /notebooks/KorBertSum/models/bert_classifier/backup/model_step_10000.pt\n",
      "[2022-04-23 20:33:22,389 INFO] loading archive file /notebooks/model/001_bert_morp_pytorch\n",
      "[2022-04-23 20:33:22,394 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-23 20:33:25,449 INFO] * number of parameters: 109350145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-23 20:33:30,386 INFO] Loading checkpoint from /notebooks/KorBertSum/models/bert_classifier/backup/model_step_10000.pt\n",
      "[2022-04-23 20:33:36,335 INFO] loading archive file /notebooks/model/001_bert_morp_pytorch\n",
      "[2022-04-23 20:33:36,340 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-23 20:33:39,478 INFO] * number of parameters: 109350145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-23 20:33:44,062 INFO] Loading checkpoint from /notebooks/KorBertSum/models/bert_classifier/backup/model_step_10000.pt\n",
      "[2022-04-23 20:33:50,097 INFO] loading archive file /notebooks/model/001_bert_morp_pytorch\n",
      "[2022-04-23 20:33:50,103 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-23 20:33:53,346 INFO] * number of parameters: 109350145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-23 20:33:58,467 INFO] Loading checkpoint from /notebooks/KorBertSum/models/bert_classifier/backup/model_step_10000.pt\n",
      "[2022-04-23 20:34:04,588 INFO] loading archive file /notebooks/model/001_bert_morp_pytorch\n",
      "[2022-04-23 20:34:04,594 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-23 20:34:07,673 INFO] * number of parameters: 109350145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-23 20:34:12,229 INFO] Loading checkpoint from /notebooks/KorBertSum/models/bert_classifier/backup/model_step_10000.pt\n",
      "[2022-04-23 20:34:17,951 INFO] loading archive file /notebooks/model/001_bert_morp_pytorch\n",
      "[2022-04-23 20:34:17,957 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-23 20:34:20,912 INFO] * number of parameters: 109350145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-23 20:34:25,406 INFO] Loading checkpoint from /notebooks/KorBertSum/models/bert_classifier/backup/model_step_10000.pt\n",
      "[2022-04-23 20:34:30,835 INFO] loading archive file /notebooks/model/001_bert_morp_pytorch\n",
      "[2022-04-23 20:34:30,839 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-23 20:34:33,777 INFO] * number of parameters: 109350145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-23 20:34:38,732 INFO] Loading checkpoint from /notebooks/KorBertSum/models/bert_classifier/backup/model_step_10000.pt\n",
      "[2022-04-23 20:34:44,753 INFO] loading archive file /notebooks/model/001_bert_morp_pytorch\n",
      "[2022-04-23 20:34:44,757 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-23 20:34:47,815 INFO] * number of parameters: 109350145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-23 20:34:53,162 INFO] Loading checkpoint from /notebooks/KorBertSum/models/bert_classifier/backup/model_step_10000.pt\n",
      "[2022-04-23 20:34:59,319 INFO] loading archive file /notebooks/model/001_bert_morp_pytorch\n",
      "[2022-04-23 20:34:59,324 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-23 20:35:02,422 INFO] * number of parameters: 109350145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-23 20:35:07,138 INFO] Loading checkpoint from /notebooks/KorBertSum/models/bert_classifier/backup/model_step_10000.pt\n",
      "[2022-04-23 20:35:13,202 INFO] loading archive file /notebooks/model/001_bert_morp_pytorch\n",
      "[2022-04-23 20:35:13,207 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-23 20:35:16,187 INFO] * number of parameters: 109350145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-23 20:35:21,179 INFO] Loading checkpoint from /notebooks/KorBertSum/models/bert_classifier/backup/model_step_10000.pt\n",
      "[2022-04-23 20:35:27,422 INFO] loading archive file /notebooks/model/001_bert_morp_pytorch\n",
      "[2022-04-23 20:35:27,426 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-23 20:35:30,697 INFO] * number of parameters: 109350145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-23 20:35:35,670 INFO] Loading checkpoint from /notebooks/KorBertSum/models/bert_classifier/backup/model_step_10000.pt\n",
      "[2022-04-23 20:35:41,958 INFO] loading archive file /notebooks/model/001_bert_morp_pytorch\n",
      "[2022-04-23 20:35:41,964 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-23 20:35:45,075 INFO] * number of parameters: 109350145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-23 20:35:49,800 INFO] Loading checkpoint from /notebooks/KorBertSum/models/bert_classifier/backup/model_step_10000.pt\n",
      "[2022-04-23 20:35:55,643 INFO] loading archive file /notebooks/model/001_bert_morp_pytorch\n",
      "[2022-04-23 20:35:55,647 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-23 20:35:58,692 INFO] * number of parameters: 109350145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-23 20:36:03,673 INFO] Loading checkpoint from /notebooks/KorBertSum/models/bert_classifier/backup/model_step_10000.pt\n",
      "[2022-04-23 20:36:09,223 INFO] loading archive file /notebooks/model/001_bert_morp_pytorch\n",
      "[2022-04-23 20:36:09,228 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n",
      "[2022-04-23 20:36:12,401 INFO] * number of parameters: 109350145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    }
   ],
   "source": [
    "news_df['sum_article'] = news_df.news_article.apply(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd1c651-cf2e-4c1f-a32c-c8be06ef6ddb",
   "metadata": {},
   "source": [
    "## import to Amazon RDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4b88f5-c1b8-4963-ad9d-504a11771c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "news_df_rds = news_df[['news_source','news_date','news_url','news_title','news_img','sum_article']]\n",
    "news_df_rds.columns = ['news_source','news_date','news_url','news_title','news_image','news_article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67042f8f-08a9-488b-be39-46745ec52804",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_source</th>\n",
       "      <th>news_date</th>\n",
       "      <th>news_url</th>\n",
       "      <th>news_title</th>\n",
       "      <th>news_image</th>\n",
       "      <th>news_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>어린이조선일보</td>\n",
       "      <td>2022-04-19 00:01</td>\n",
       "      <td>http://kid.chosun.com/site/data/html_dir/2022/...</td>\n",
       "      <td>아메리카 인디언의 벌새 전설 기생충과 박테리아</td>\n",
       "      <td>http://kid.chosun.com/site/data/img_dir/2022/0...</td>\n",
       "      <td>기겁한 동물들이 사방으로 흩어져 달아났다\\n\\n그런데 유독 한 동물만은 자리를 지켰...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  news_source         news_date  \\\n",
       "0     어린이조선일보  2022-04-19 00:01   \n",
       "\n",
       "                                            news_url  \\\n",
       "0  http://kid.chosun.com/site/data/html_dir/2022/...   \n",
       "\n",
       "                  news_title  \\\n",
       "0  아메리카 인디언의 벌새 전설 기생충과 박테리아   \n",
       "\n",
       "                                          news_image  \\\n",
       "0  http://kid.chosun.com/site/data/img_dir/2022/0...   \n",
       "\n",
       "                                        news_article  \n",
       "0  기겁한 동물들이 사방으로 흩어져 달아났다\\n\\n그런데 유독 한 동물만은 자리를 지켰...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df_rds.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2127d6b-9bca-4def-9d9a-4b4dee0d09ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df_rds.to_csv('/notebooks/news_df_rds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5750044-f7d4-453b-8642-45ad41f8ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('/notebooks/news_df_rds.csv',sep=',').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b3138e0-9cef-4631-a6dd-f77cd3fb48be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_source</th>\n",
       "      <th>news_date</th>\n",
       "      <th>news_url</th>\n",
       "      <th>news_title</th>\n",
       "      <th>news_image</th>\n",
       "      <th>news_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>어린이조선일보</td>\n",
       "      <td>2022-04-19 00:01</td>\n",
       "      <td>http://kid.chosun.com/site/data/html_dir/2022/...</td>\n",
       "      <td>아메리카 인디언의 벌새 전설 기생충과 박테리아</td>\n",
       "      <td>http://kid.chosun.com/site/data/img_dir/2022/0...</td>\n",
       "      <td>기겁한 동물들이 사방으로 흩어져 달아났다\\n\\n그런데 유독 한 동물만은 자리를 지켰...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  news_source         news_date  \\\n",
       "0     어린이조선일보  2022-04-19 00:01   \n",
       "\n",
       "                                            news_url  \\\n",
       "0  http://kid.chosun.com/site/data/html_dir/2022/...   \n",
       "\n",
       "                  news_title  \\\n",
       "0  아메리카 인디언의 벌새 전설 기생충과 박테리아   \n",
       "\n",
       "                                          news_image  \\\n",
       "0  http://kid.chosun.com/site/data/img_dir/2022/0...   \n",
       "\n",
       "                                        news_article  \n",
       "0  기겁한 동물들이 사방으로 흩어져 달아났다\\n\\n그런데 유독 한 동물만은 자리를 지켰...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22c4fed2-c0bc-405d-a06f-4f16fa21d28d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "db_connection_str = 'mysql+pymysql://root:1234@172.19.0.2:3306/news-kids'\n",
    "db_connection = create_engine(db_connection_str)\n",
    "conn = db_connection.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "365cd1d3-fb2e-4df3-8760-54ffcdcc948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df_rds.to_sql(name='news', con=db_connection, if_exists='append',index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
